{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/create-a-neural-network-with-pytorch-lightning-in-just-100-lines-of-code-43eccbf3fba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMENTARIOS DE CÓMO ESTA LA COSA:\n",
    "### Domingo 5 de marzo\n",
    "\n",
    "He probado a usar el `random_transform` porque en el test con el `iter` del final no le molaba que le metiera un tensor o no sé qué. Este, en vez de usar el `train_test_split` de sklearn, no tengo controlado cómo se normalia y entonces la métrica r2 ha salido como la mierda (8).\n",
    "\n",
    "- ver si conviene volver a convertirlos en tensor después de hacerles el escalado.\n",
    "\n",
    "- que eso sea compatible con el `inverse_transform` del final para poder meterlo al controlador de verdad.\n",
    "\n",
    "- comparar la respuesta que nos darían los outputs reales con la predicción; volviéndolos a meter en matlab.\n",
    "\n",
    "### Lunes\n",
    "Fixed cosas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDataset(Dataset):\n",
    "    \"Geting features and outputs ndarray from file.\"\n",
    "    def __init__(self, filename, ninputs, noutputs, delimiter: str=','):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(filename, delimiter=delimiter, dtype=np.float32)\n",
    "        self.X = xy[:,:ninputs]\n",
    "        self.y = xy[:,ninputs:ninputs+noutputs]\n",
    "        self.n_samples = xy.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "class DatasetFromXy(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.n_samples = X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  800\n",
      "Number of testing samples:   200\n"
     ]
    }
   ],
   "source": [
    "# DATASET GENERATION\n",
    "filename = 'datasetUAV_Controller_v0.csv'\n",
    "ninputs = 4\n",
    "noutputs = 8\n",
    "\n",
    "data_prov = GetDataset(filename=filename, ninputs=ninputs, noutputs=noutputs)\n",
    "\n",
    "X = data_prov.X\n",
    "y = data_prov.y\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "scalery = StandardScaler()\n",
    "X_scaled = scalerX.fit_transform(X)\n",
    "y_scaled = scalery.fit_transform(y)\n",
    "\n",
    "data = DatasetFromXy(X_scaled, y_scaled)\n",
    "\n",
    "test_set, train_set = random_split(data, lengths=[.2,.8], generator=torch.Generator())\n",
    "\n",
    "print(f'Number of training samples: {len(train_set):4}\\nNumber of testing samples: {len(test_set):5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATALOADERS AND TRAIN/TEST BATCHES\n",
    "\n",
    "train_batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK DEFINITION\n",
    "class Network(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, learning_rate, drop_p=0.5):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer\n",
    "            output_size: integer, size of the output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "        \n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "\n",
    "        self.loss_fun = nn.MSELoss()    # Mean Squared Error\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        \"Definition of the training loop.\"\n",
    "        X, y = train_batch                  # (extracting features and outputs)\n",
    "        # y = y.type(torch.float32)           # (just in case)\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()  # \n",
    "        # compute loss\n",
    "        loss = self.loss_fun(y_pred, y)     # \n",
    "        self.log_dict({'train_loss': loss}, on_step=False, on_epoch=True, prog_bar=True, logger=True)  #5\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        # y = y.type(torch.float32)\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()        \n",
    "        # compute metrics\n",
    "        r2 = r2_score(y_pred, y)\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred, y))\n",
    "        loss = self.loss_fun(y_pred, y)\n",
    "        self.log_dict({'test_loss': loss, 'r2': r2, 'rmse': rmse}, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK DEFINITION\n",
    "\n",
    "# Number of layers and their sizes:\n",
    "input_size = data.X.shape[1]\n",
    "output_size = data.y.shape[1]\n",
    "hidden_layers = [32, 64, 64, 32]\n",
    "\n",
    "# Other hyperparameters:\n",
    "max_epochs = 500\n",
    "lr = 0.0001\n",
    "\n",
    "model = Network(input_size=input_size, output_size=output_size, hidden_layers=hidden_layers, learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including early stoping: `patience` is the key parameter here.\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=20, verbose=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | hidden_layers | ModuleList | 8.5 K \n",
      "1 | output        | Linear     | 264   \n",
      "2 | dropout       | Dropout    | 0     \n",
      "3 | loss_fun      | MSELoss    | 0     \n",
      "---------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824971b34f104b1c83ed065e97a9f263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 1.012\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 1.006\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 1.004\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.004\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 1.000\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.999\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.997\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.994\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.990\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.986\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.984\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.980\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.979\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.975\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.973\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.971\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.969\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.965\n",
      "Metric train_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.948\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.934\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.931\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.930\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.924\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.916\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.904\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.890\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.884\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.875\n",
      "Metric train_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.862\n",
      "Metric train_loss improved by 0.018 >= min_delta = 0.0. New best score: 0.843\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.837\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.822\n",
      "Metric train_loss improved by 0.010 >= min_delta = 0.0. New best score: 0.812\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.801\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.798\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.790\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.788\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.782\n",
      "Metric train_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.766\n",
      "Metric train_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.747\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.746\n",
      "Metric train_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.721\n",
      "Metric train_loss improved by 0.017 >= min_delta = 0.0. New best score: 0.704\n",
      "Metric train_loss improved by 0.016 >= min_delta = 0.0. New best score: 0.688\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.683\n",
      "Metric train_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.659\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.648\n",
      "Metric train_loss improved by 0.030 >= min_delta = 0.0. New best score: 0.618\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.614\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.613\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.605\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.602\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.595\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.591\n",
      "Metric train_loss improved by 0.018 >= min_delta = 0.0. New best score: 0.573\n",
      "Metric train_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.565\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.564\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.553\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.539\n",
      "Metric train_loss improved by 0.011 >= min_delta = 0.0. New best score: 0.527\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.516\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.514\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.500\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.492\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.484\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.482\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.480\n",
      "`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='cpu', devices=1, max_epochs=max_epochs, callbacks=[early_stop_callback], log_every_n_steps=8)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:488: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492e7a9b93754f35b501fdf9150583a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            r2             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   -0.24934509304844404    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">           rmse            </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5594537854194641     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.31400179862976074    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           r2            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  -0.24934509304844404   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m          rmse           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5594537854194641    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.31400179862976074   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.31400179862976074,\n",
       "  'r2': -0.24934509304844404,\n",
       "  'rmse': 0.5594537854194641}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particular Examples: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictController(trim, model, scalerX=scalerX, scalery=scalery):\n",
    "    \"\"\"\n",
    "    Function that receives the trim state vector and generates a prediction of the appropriate\n",
    "    controller based on the trained model 'model'.\n",
    "    \"\"\"\n",
    "    trim = np.array(trim).reshape(1,-1)\n",
    "    features = scalerX.fit_transform(trim)\n",
    "    out_pred = model(torch.Tensor(features))\n",
    "    K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "    state_dim = K_comps.size\n",
    "    return K_comps.reshape(2,int(state_dim/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3987778   0.13895741 -0.4560663  -0.00531475]\n",
      " [ 0.03745402  1.380272   -0.8348239  -0.2421587 ]]\n"
     ]
    }
   ],
   "source": [
    "trim = [18, 9.73, 1, 6]\n",
    "K = PredictController(trim, model)\n",
    "print(K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "da38062997892a68ae88df3a1549a85ff68f4e3a875c1f51aead31b07f2af4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

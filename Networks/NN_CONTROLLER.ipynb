{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/create-a-neural-network-with-pytorch-lightning-in-just-100-lines-of-code-43eccbf3fba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NN_CONTROLLER**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# saving models\n",
    "import torch.onnx\n",
    "import onnx\n",
    "\n",
    "\n",
    "# logging metrics output\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# import tensorboard\n",
    "\n",
    "# else:\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDataset(Dataset):\n",
    "    \"Geting features and outputs ndarray from file.\"\n",
    "    def __init__(self, filename, ninputs, noutputs, delimiter: str=','):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(filename, delimiter=delimiter, dtype=np.float32)\n",
    "        self.X = xy[:, :ninputs]\n",
    "        self.y = xy[:, ninputs:ninputs+noutputs]\n",
    "        self.n_samples = xy.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "class DatasetFromXy(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.n_samples = X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:    7\n",
      "Number of testing samples:     2\n"
     ]
    }
   ],
   "source": [
    "# DATASET GENERATION\n",
    "# filename = '../Datasets/dataset_5D_002.csv'\n",
    "filename = '../Datasets/dataset_009.csv'\n",
    "ninputs = 2\n",
    "noutputs = 10\n",
    "\n",
    "data_raw = GetDataset(filename=filename, ninputs=ninputs, noutputs=noutputs)\n",
    "X_raw = data_raw.X\n",
    "y_raw = data_raw.y\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "X_scaled = scalerX.fit_transform(X_raw)\n",
    "\n",
    "data_scaled = DatasetFromXy(X_scaled, y_raw)\n",
    "\n",
    "test_set, train_set = random_split(data_scaled, lengths=[.2,.8], generator=torch.Generator())\n",
    "nsamples = len(test_set)\n",
    "\n",
    "print(f'Number of training samples: {len(train_set):4}\\nNumber of testing samples: {len(test_set):5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATALOADERS AND TRAIN/TEST BATCHES\n",
    "train_batch_size = 4  # 400 para dataset_005, ~30 para dataset_006\n",
    "test_batch_size = 10    # nos da igual\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK DEFINITION\n",
    "class Network(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, learning_rate, drop_p=0.2, leaky_slope=0.0):\n",
    "        ''' Builds a fully connected network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer.\n",
    "            output_size: integer, size of the output layer.\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers.\n",
    "            learning_rate: learning rate for the optimizer.\n",
    "            drop_p: float = 0.2, drop out probability.\n",
    "            leacky_slope: float = 0.0 slope of the leakyReLU activation function. A value of zero is\n",
    "            equivalent to using the ReLU function.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_sizes = hidden_layers\n",
    "        self.structure_dict = {'input_size': input_size,\n",
    "                               'output_size': output_size,\n",
    "                               'hidden_sizes': hidden_layers}\n",
    "\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        # Ouput layer\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        # Dropout probabilty\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "\n",
    "        # LeakyReLU activation function negative slope\n",
    "        self.leaky_slope = leaky_slope\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_fun = nn.MSELoss()    # Mean Squared Error Loss\n",
    "\n",
    "        # Optimizer learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # optimizer:\n",
    "        self.optimizer = []\n",
    "\n",
    "        # new: ########################\n",
    "        self.last_test_loss = 0\n",
    "\n",
    "        # extra: monitoring training loss\n",
    "        # self.training_loss = []\n",
    "        # self.test_batch_idx = []\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits.'''\n",
    "        for each in self.hidden_layers:\n",
    "            # x = F.relu(each(x))\n",
    "            x = F.leaky_relu(each(x), self.leaky_slope)\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        self.optimizer = optimizer\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        \"Definition of the training loop.\"\n",
    "        X, y = train_batch                  # (extracting features and outputs)\n",
    "        # y = y.type(torch.float32)         # (just in case)\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()  # \n",
    "        # compute loss\n",
    "        loss = self.loss_fun(y_pred, y)     # \n",
    "        self.log_dict({'train_loss': loss}, on_step=False, on_epoch=True, prog_bar=True,\n",
    "                      logger=True, enable_graph=True)\n",
    "        \n",
    "        # extra: monitoring training loss:\n",
    "        # self.training_loss.append(np.mean(loss.item()))\n",
    "        # self.test_batch_idx.append(batch_idx)\n",
    "        # extra:\n",
    "        # writer.add_scalar('Train Loss', loss)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()        \n",
    "        # compute metrics\n",
    "        loss = self.loss_fun(y_pred, y)\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred, y))\n",
    "        r2 = r2_score(y_pred, y)\n",
    "\n",
    "        self.last_test_loss = loss\n",
    "\n",
    "        self.log_dict({'Cost function': loss},\n",
    "                      on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # self.log_dict({'Cost function': loss, 'r2': r2, 'Root Mean Square Error': rmse},\n",
    "                    #   on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RUN: ALL DEF+TRAIN+TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | hidden_layers | ModuleList | 3.4 K \n",
      "1 | output        | Linear     | 210   \n",
      "2 | dropout       | Dropout    | 0     \n",
      "3 | loss_fun      | MSELoss    | 0     \n",
      "---------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=8). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1ad0a7488e4b94ba1905260f934aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 1.278\n",
      "Metric train_loss improved by 0.070 >= min_delta = 0.0. New best score: 1.208\n",
      "Metric train_loss improved by 0.072 >= min_delta = 0.0. New best score: 1.136\n",
      "Metric train_loss improved by 0.096 >= min_delta = 0.0. New best score: 1.039\n",
      "Metric train_loss improved by 0.129 >= min_delta = 0.0. New best score: 0.910\n",
      "Metric train_loss improved by 0.154 >= min_delta = 0.0. New best score: 0.756\n",
      "Metric train_loss improved by 0.168 >= min_delta = 0.0. New best score: 0.589\n",
      "Metric train_loss improved by 0.132 >= min_delta = 0.0. New best score: 0.457\n",
      "Metric train_loss improved by 0.073 >= min_delta = 0.0. New best score: 0.384\n",
      "Metric train_loss improved by 0.050 >= min_delta = 0.0. New best score: 0.334\n",
      "Metric train_loss improved by 0.056 >= min_delta = 0.0. New best score: 0.277\n",
      "Metric train_loss improved by 0.062 >= min_delta = 0.0. New best score: 0.216\n",
      "Metric train_loss improved by 0.031 >= min_delta = 0.0. New best score: 0.185\n",
      "Metric train_loss improved by 0.027 >= min_delta = 0.0. New best score: 0.158\n",
      "Metric train_loss improved by 0.019 >= min_delta = 0.0. New best score: 0.139\n",
      "Metric train_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.113\n",
      "Metric train_loss improved by 0.012 >= min_delta = 0.0. New best score: 0.101\n",
      "Metric train_loss improved by 0.018 >= min_delta = 0.0. New best score: 0.083\n",
      "Metric train_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.062\n",
      "Metric train_loss improved by 0.014 >= min_delta = 0.0. New best score: 0.048\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.034\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.026\n",
      "Metric train_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.021\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.018\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.014\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.010\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.010\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.009\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.008\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.006\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Monitored metric train_loss did not improve in the last 20 records. Best score: 0.000. Signaling Trainer to stop.\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e127f3e3dc4029902220a98b8302e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Cost function         0.05456965044140816\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Cost function': 0.05456965044140816}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NETWORK DEFINITION\n",
    "# Number of layers and their sizes:\n",
    "input_size = ninputs\n",
    "output_size = noutputs\n",
    "hidden_layers = [10]\n",
    "hidden_layers = [20]\n",
    "hidden_layers = [20, 20]\n",
    "hidden_layers = [20, 40, 20]\n",
    "hidden_layers = [20, 40, 40, 20]\n",
    "# Other hyperparameters:\n",
    "max_epochs = 2000\n",
    "lr = 0.005\n",
    "drop_p = 0.\n",
    "leaky_slope = 0.0\n",
    "\n",
    "model = Network(input_size=input_size, output_size=output_size, hidden_layers=hidden_layers,\n",
    "                learning_rate=lr, drop_p=drop_p, leaky_slope=leaky_slope)\n",
    "\n",
    "patience = 20\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=patience, verbose=True, mode=\"min\")\n",
    "# DEFINITION OF THE TRAINER\n",
    "trainer = pl.Trainer(accelerator='cpu', devices='auto', max_epochs=max_epochs,\n",
    "                     callbacks=[early_stop_callback], log_every_n_steps=8, deterministic=True)\n",
    "\n",
    "# TRAINING\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "# TESTING\n",
    "trainer.test(model=model, dataloaders=test_loader)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK DEFINITION\n",
    "\n",
    "# Number of layers and their sizes:\n",
    "input_size = ninputs\n",
    "output_size = noutputs\n",
    "hidden_layers = [10]\n",
    "\n",
    "# Other hyperparameters:\n",
    "max_epochs = 1000\n",
    "lr = 0.005\n",
    "drop_p = 0.\n",
    "\n",
    "leaky_slope = 0.0\n",
    "\n",
    "model = Network(input_size=input_size, output_size=output_size, hidden_layers=hidden_layers,\n",
    "                learning_rate=lr, drop_p=drop_p, leaky_slope=leaky_slope)\n",
    "\n",
    "# Including early stoping: `patience` is the key parameter here.\n",
    "patience = 20\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=patience, verbose=True, mode=\"min\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | hidden_layers | ModuleList | 60    \n",
      "1 | output        | Linear     | 210   \n",
      "2 | dropout       | Dropout    | 0     \n",
      "3 | loss_fun      | MSELoss    | 0     \n",
      "---------------------------------------------\n",
      "270       Trainable params\n",
      "0         Non-trainable params\n",
      "270       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=8). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba3c3a6a9ec4560aa759844c58662da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 1.305\n",
      "Metric train_loss improved by 0.182 >= min_delta = 0.0. New best score: 1.123\n",
      "Metric train_loss improved by 0.152 >= min_delta = 0.0. New best score: 0.971\n",
      "Metric train_loss improved by 0.131 >= min_delta = 0.0. New best score: 0.841\n",
      "Metric train_loss improved by 0.111 >= min_delta = 0.0. New best score: 0.729\n",
      "Metric train_loss improved by 0.099 >= min_delta = 0.0. New best score: 0.630\n",
      "Metric train_loss improved by 0.091 >= min_delta = 0.0. New best score: 0.540\n",
      "Metric train_loss improved by 0.075 >= min_delta = 0.0. New best score: 0.464\n",
      "Metric train_loss improved by 0.070 >= min_delta = 0.0. New best score: 0.394\n",
      "Metric train_loss improved by 0.064 >= min_delta = 0.0. New best score: 0.330\n",
      "Metric train_loss improved by 0.050 >= min_delta = 0.0. New best score: 0.279\n",
      "Metric train_loss improved by 0.048 >= min_delta = 0.0. New best score: 0.231\n",
      "Metric train_loss improved by 0.037 >= min_delta = 0.0. New best score: 0.195\n",
      "Metric train_loss improved by 0.037 >= min_delta = 0.0. New best score: 0.157\n",
      "Metric train_loss improved by 0.025 >= min_delta = 0.0. New best score: 0.133\n",
      "Metric train_loss improved by 0.022 >= min_delta = 0.0. New best score: 0.111\n",
      "Metric train_loss improved by 0.018 >= min_delta = 0.0. New best score: 0.093\n",
      "Metric train_loss improved by 0.008 >= min_delta = 0.0. New best score: 0.085\n",
      "Metric train_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.075\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.070\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.065\n",
      "Metric train_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.061\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.058\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.055\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.051\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.049\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.046\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.044\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.043\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.041\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.039\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.038\n",
      "Metric train_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.037\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.036\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.034\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.033\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.032\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.031\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.030\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.029\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.028\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.027\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.026\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.026\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.025\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.024\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.023\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.023\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.022\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.022\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.021\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.020\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.019\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.019\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.018\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.018\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.017\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.017\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.016\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.016\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.015\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.015\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.014\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.014\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.014\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.013\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.013\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.012\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.012\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.012\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.011\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.011\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.011\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.011\n",
      "Metric train_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.010\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.010\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.009\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.009\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.009\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.009\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.008\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.008\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.008\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.008\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.007\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.006\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.005\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.004\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.003\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.002\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.001\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Metric train_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.000\n",
      "Monitored metric train_loss did not improve in the last 20 records. Best score: 0.000. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "# DEFINITION OF THE TRAINER\n",
    "trainer = pl.Trainer(accelerator='cpu', devices='auto', max_epochs=max_epochs,\n",
    "                     callbacks=[early_stop_callback], log_every_n_steps=8, deterministic=True)\n",
    "\n",
    "# TRAINING\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "# writer.flush()\n",
    "# writer.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff764bccfdaa455cbfaba5c17cc53a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Cost function        0.0010673918295651674\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[{'Cost function': 0.0010673918295651674}]\n"
     ]
    }
   ],
   "source": [
    "# TEST OUTPUT\n",
    "print(trainer.test(model=model, dataloaders=test_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Loading Model to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/scalerX_009.bin']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- IDENTIFIER ------\n",
    "identifier = '009_20_40_40_20'\n",
    "# ------ -------- -------\n",
    "\n",
    "# SAVING THE STATE DICT\n",
    "state_dict_path = '../Models/' + 'state_dict_' + identifier\n",
    "torch.save(model.state_dict(), state_dict_path)\n",
    "\n",
    "# SAVING THE STRUCTURE DICT\n",
    "structure_dict = model.structure_dict\n",
    "dump(structure_dict, '../Models/' + 'structure_' + identifier, compress=True)\n",
    "\n",
    "# SAVING THE STANDARD SCALER\n",
    "dump(scalerX, '../Models/scalerX_' + identifier[0:3] + '.bin', compress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "hidden_layers.0.weight \t torch.Size([20, 2])\n",
      "hidden_layers.0.bias \t torch.Size([20])\n",
      "hidden_layers.1.weight \t torch.Size([40, 20])\n",
      "hidden_layers.1.bias \t torch.Size([40])\n",
      "hidden_layers.2.weight \t torch.Size([40, 40])\n",
      "hidden_layers.2.bias \t torch.Size([40])\n",
      "hidden_layers.3.weight \t torch.Size([20, 40])\n",
      "hidden_layers.3.bias \t torch.Size([20])\n",
      "output.weight \t torch.Size([10, 20])\n",
      "output.bias \t torch.Size([10])\n",
      "\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(21.), 'exp_avg': tensor([[-4.1757e-03, -4.4490e-03],\n",
      "        [ 1.9473e-03, -1.2747e-03],\n",
      "        [-7.8532e-03, -6.6654e-03],\n",
      "        [-4.8333e-04,  2.4932e-03],\n",
      "        [ 5.7345e-03, -7.8494e-04],\n",
      "        [ 7.4421e-04,  6.1482e-03],\n",
      "        [ 7.1190e-03, -6.3492e-03],\n",
      "        [ 2.3397e-03,  1.6157e-03],\n",
      "        [-2.6480e-03,  2.2710e-03],\n",
      "        [ 8.2957e-04, -1.2661e-03],\n",
      "        [ 2.7800e-03,  3.3480e-03],\n",
      "        [-3.9422e-03, -2.4990e-03],\n",
      "        [-7.4738e-04, -8.9402e-04],\n",
      "        [-6.4684e-05,  7.9290e-04],\n",
      "        [-1.3665e-03,  8.0152e-04],\n",
      "        [ 1.2328e-03, -9.3619e-04],\n",
      "        [ 7.1697e-04,  2.3214e-03],\n",
      "        [-1.8966e-05, -1.1414e-03],\n",
      "        [ 2.1418e-03, -7.3845e-03],\n",
      "        [-1.8993e-03,  1.1235e-03]]), 'exp_avg_sq': tensor([[3.4618e-07, 4.9166e-07],\n",
      "        [9.7395e-08, 3.7636e-08],\n",
      "        [1.2726e-06, 1.1237e-06],\n",
      "        [4.4528e-08, 1.3115e-07],\n",
      "        [8.3612e-07, 2.8069e-08],\n",
      "        [5.7102e-08, 7.4390e-07],\n",
      "        [1.0744e-06, 8.3837e-07],\n",
      "        [1.2499e-07, 5.7960e-08],\n",
      "        [1.6046e-07, 1.0721e-07],\n",
      "        [2.1865e-08, 3.5158e-08],\n",
      "        [1.7679e-07, 2.2950e-07],\n",
      "        [1.1058e-06, 2.8106e-07],\n",
      "        [1.9808e-08, 2.2083e-08],\n",
      "        [1.8388e-08, 1.6204e-08],\n",
      "        [4.9207e-08, 5.4014e-08],\n",
      "        [3.5698e-08, 2.0332e-08],\n",
      "        [2.6137e-08, 1.2911e-07],\n",
      "        [2.9404e-09, 2.7630e-08],\n",
      "        [1.3638e-07, 1.1619e-06],\n",
      "        [7.9909e-08, 5.7596e-08]])}, 1: {'step': tensor(21.), 'exp_avg': tensor([-0.0086, -0.0019, -0.0171, -0.0002, -0.0042, -0.0050, -0.0165, -0.0026,\n",
      "        -0.0023, -0.0011, -0.0038, -0.0277, -0.0007,  0.0002, -0.0004, -0.0012,\n",
      "         0.0029, -0.0010, -0.0071, -0.0017]), 'exp_avg_sq': tensor([1.4548e-06, 8.7903e-08, 5.6878e-06, 6.8518e-08, 4.3962e-07, 5.0360e-07,\n",
      "        5.3699e-06, 1.3815e-07, 1.1630e-07, 2.7501e-08, 3.1291e-07, 1.4782e-05,\n",
      "        1.5938e-08, 1.1351e-08, 6.9912e-08, 3.1313e-08, 2.2618e-07, 2.2232e-08,\n",
      "        1.1156e-06, 5.8626e-08])}, 2: {'step': tensor(21.), 'exp_avg': tensor([[-1.0242e-04, -1.6092e-05, -3.1317e-04, -2.1029e-03, -2.3330e-05,\n",
      "         -7.0986e-04, -3.7713e-04, -1.6458e-03, -8.9551e-05, -1.5026e-07,\n",
      "         -1.5225e-03, -5.9100e-04,  4.9209e-08, -1.0739e-03, -3.2647e-04,\n",
      "         -9.2434e-06, -2.1446e-03,  0.0000e+00, -5.1850e-07, -4.9569e-05],\n",
      "        [-1.6180e-02, -4.3498e-03, -1.6178e-02, -1.4470e-02, -5.1064e-04,\n",
      "         -2.1463e-03, -1.0378e-02, -7.5614e-03, -6.5050e-03, -4.4361e-03,\n",
      "         -6.3333e-03, -1.8866e-02, -4.3304e-03, -8.1861e-03, -2.2886e-02,\n",
      "         -1.8045e-03, -1.7219e-02, -5.0389e-03, -5.5811e-03, -7.1119e-03],\n",
      "        [ 4.0681e-03,  4.7141e-05,  4.0653e-03,  5.1177e-03,  1.0986e-05,\n",
      "          6.9677e-04,  5.9376e-04,  1.6101e-03,  2.2226e-03,  3.1533e-04,\n",
      "          1.0575e-03,  3.3004e-03,  1.1811e-03,  3.0715e-03,  5.8738e-03,\n",
      "          1.3040e-05,  5.9886e-03,  7.0877e-04,  3.2705e-04,  2.3923e-03],\n",
      "        [-3.6576e-03, -5.8058e-04, -3.5078e-03, -2.2123e-03, -3.2030e-05,\n",
      "         -4.1078e-05, -1.3841e-03, -4.1096e-04, -1.3415e-03, -7.9014e-04,\n",
      "         -1.2911e-04, -3.3669e-03, -9.8942e-04, -1.3300e-03, -4.6858e-03,\n",
      "         -1.9168e-04, -3.0423e-03, -1.0803e-03, -9.7938e-04, -1.4485e-03],\n",
      "        [-1.0527e-02, -2.8183e-03, -1.0832e-02, -1.3502e-02, -3.2561e-04,\n",
      "         -2.5317e-03, -6.5240e-03, -6.3308e-03, -5.1147e-03, -2.6840e-03,\n",
      "         -5.1106e-03, -1.2132e-02, -2.6091e-03, -8.0167e-03, -1.5675e-02,\n",
      "         -1.1527e-03, -1.5201e-02, -3.0742e-03, -3.5945e-03, -5.5125e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5501e-04, -1.7841e-04,  2.2508e-04,  9.2792e-04, -3.0256e-05,\n",
      "          1.8745e-04, -2.5190e-04,  2.1293e-04,  1.4708e-04, -1.0726e-04,\n",
      "          8.0444e-05, -2.2184e-05,  6.0371e-06,  5.7851e-04,  2.1170e-04,\n",
      "         -1.2267e-04,  1.1233e-03, -4.7429e-05, -1.5953e-04,  1.6744e-04],\n",
      "        [-9.1754e-03, -2.4656e-03, -9.3165e-03, -6.4705e-03, -1.6562e-04,\n",
      "         -3.7404e-04, -5.1390e-03, -1.4229e-03, -3.4803e-03, -2.7067e-03,\n",
      "         -4.8919e-04, -9.4207e-03, -2.3960e-03, -3.5842e-03, -1.1814e-02,\n",
      "         -9.7678e-04, -7.1830e-03, -3.2385e-03, -3.4496e-03, -3.6961e-03],\n",
      "        [-8.0920e-03, -2.0579e-03, -8.3691e-03, -1.0558e-02, -2.3117e-04,\n",
      "         -1.6781e-03, -4.5082e-03, -4.2066e-03, -3.8521e-03, -1.8762e-03,\n",
      "         -3.0730e-03, -8.4873e-03, -1.7862e-03, -6.2994e-03, -1.1034e-02,\n",
      "         -8.5918e-04, -1.2187e-02, -2.2333e-03, -2.5611e-03, -4.1156e-03],\n",
      "        [-2.9411e-03, -1.8438e-03, -2.8904e-03, -1.4180e-03, -2.0907e-04,\n",
      "         -6.0416e-04, -3.4978e-03, -1.6358e-03, -6.8437e-04, -1.7217e-03,\n",
      "         -1.9796e-03, -4.0362e-03, -8.3111e-04, -5.6154e-04, -4.1683e-03,\n",
      "         -7.1424e-04, -1.8059e-03, -1.9072e-03, -2.2794e-03, -8.4153e-04],\n",
      "        [ 1.2750e-04,  1.7168e-04,  1.4339e-04,  1.2050e-04,  1.3624e-05,\n",
      "          6.0112e-06,  4.8587e-05,  2.5875e-05,  8.5244e-05,  9.3592e-05,\n",
      "          2.4064e-05,  2.4008e-04,  3.9903e-05,  5.7467e-05,  2.5908e-04,\n",
      "          9.7101e-05,  1.3426e-05,  6.3778e-05,  1.8977e-04,  8.3314e-05],\n",
      "        [-4.9578e-03, -5.7322e-04, -4.9559e-03, -3.7673e-03, -9.4092e-06,\n",
      "         -3.9267e-04, -1.3513e-03, -6.9620e-04, -2.0997e-03, -8.0332e-04,\n",
      "         -1.1986e-04, -4.0287e-03, -1.1352e-03, -2.7493e-03, -6.4596e-03,\n",
      "         -1.0119e-04, -5.1186e-03, -1.3938e-03, -1.1138e-03, -2.2822e-03],\n",
      "        [-8.4284e-04,  1.6963e-04, -8.3577e-04, -1.9470e-03,  4.4294e-06,\n",
      "         -3.3846e-04,  2.1291e-05, -8.2882e-04, -5.0160e-04,  9.2992e-05,\n",
      "         -4.4711e-04, -7.0929e-04, -1.9692e-04, -1.1495e-03, -1.2786e-03,\n",
      "          8.0158e-05, -2.3731e-03,  2.2289e-05,  1.6869e-04, -5.7000e-04],\n",
      "        [ 2.5342e-04,  4.3225e-05,  2.5090e-04,  2.6300e-05,  1.5435e-06,\n",
      "          2.2178e-05,  8.2911e-05,  7.2811e-05,  1.4040e-04, -2.7691e-06,\n",
      "         -8.9537e-07,  1.6870e-04,  8.7449e-06,  2.4159e-04,  3.8783e-04,\n",
      "          1.8755e-07,  1.3239e-05,  4.9996e-05,  7.3338e-05,  1.6470e-04],\n",
      "        [-1.6109e-03, -2.0076e-03, -1.6567e-03, -1.3327e-03, -2.3681e-04,\n",
      "         -3.7914e-04, -3.8132e-03, -1.8590e-03, -1.2372e-04, -1.5048e-03,\n",
      "         -1.7071e-03, -4.1344e-03, -3.6654e-04, -3.1986e-04, -2.4416e-03,\n",
      "         -9.7305e-04, -8.7231e-04, -1.1869e-03, -2.3829e-03, -1.4280e-04],\n",
      "        [ 6.3514e-04,  2.3877e-06,  5.3907e-04,  1.2378e-03, -4.1565e-07,\n",
      "          1.0817e-04, -1.1901e-05,  1.5529e-04,  6.9902e-04,  1.7356e-05,\n",
      "          2.9164e-05,  6.5107e-04,  3.6462e-04,  7.4375e-04,  1.4792e-03,\n",
      "          1.9473e-06,  1.5102e-03,  6.6413e-05,  2.0089e-05,  7.9326e-04],\n",
      "        [-7.0532e-04, -1.1808e-03, -5.9305e-04, -2.0593e-04, -1.5695e-04,\n",
      "         -1.9755e-04, -1.9919e-03, -8.0911e-04, -6.1214e-05, -7.9359e-04,\n",
      "         -8.0382e-04, -1.8623e-03, -1.6479e-04, -1.4076e-04, -9.4870e-04,\n",
      "         -5.8302e-04, -3.3056e-04, -6.2707e-04, -1.2796e-03, -5.2739e-05],\n",
      "        [-1.2982e-02, -3.1009e-03, -1.3505e-02, -1.7280e-02, -3.7820e-04,\n",
      "         -2.7356e-03, -7.1438e-03, -6.9983e-03, -6.4483e-03, -2.8515e-03,\n",
      "         -5.3848e-03, -1.4044e-02, -3.1891e-03, -1.0046e-02, -1.8791e-02,\n",
      "         -1.3476e-03, -1.8794e-02, -3.5196e-03, -4.2657e-03, -6.9259e-03],\n",
      "        [-9.1619e-03, -2.7226e-03, -8.6651e-03, -1.5392e-03, -1.4481e-04,\n",
      "         -9.4185e-05, -5.5768e-03, -7.2246e-04, -2.6111e-03, -3.3354e-03,\n",
      "         -5.1318e-04, -9.2715e-03, -2.1758e-03, -2.2835e-03, -1.0729e-02,\n",
      "         -1.0122e-03, -3.3693e-03, -3.6417e-03, -4.0895e-03, -2.9898e-03],\n",
      "        [-3.2764e-08, -3.2745e-04, -7.6837e-06, -6.6038e-04, -1.2145e-04,\n",
      "         -2.6075e-04, -1.0392e-03, -1.2482e-03,  0.0000e+00, -7.1786e-05,\n",
      "         -1.5495e-03, -6.4636e-04,  0.0000e+00, -1.6154e-04, -9.2581e-06,\n",
      "         -1.8622e-04, -2.2477e-04, -1.4297e-05, -9.2711e-05, -1.8526e-06],\n",
      "        [-1.6922e-03, -8.2752e-04, -1.6241e-03, -9.8763e-04, -1.1159e-04,\n",
      "         -4.7225e-04, -1.8334e-03, -1.2947e-03, -3.8681e-04, -5.9537e-04,\n",
      "         -1.3467e-03, -2.3887e-03, -4.0491e-04, -6.6053e-04, -2.1102e-03,\n",
      "         -2.9651e-04, -7.2282e-04, -8.0623e-04, -1.0652e-03, -4.7409e-04],\n",
      "        [-1.0147e-02, -2.9361e-03, -1.0541e-02, -1.4599e-02, -3.6340e-04,\n",
      "         -2.7007e-03, -6.5276e-03, -6.5938e-03, -4.5772e-03, -2.5726e-03,\n",
      "         -5.3564e-03, -1.1631e-02, -2.4905e-03, -7.9162e-03, -1.4167e-02,\n",
      "         -1.2223e-03, -1.6449e-02, -3.1208e-03, -3.7314e-03, -5.0898e-03],\n",
      "        [-2.6601e-03, -1.7858e-05, -2.6517e-03, -6.2084e-04, -2.5597e-06,\n",
      "         -1.4374e-05, -3.1674e-04, -4.8194e-05, -1.1257e-03, -3.9289e-04,\n",
      "          0.0000e+00, -1.8389e-03, -1.0768e-03, -5.1083e-04, -3.1467e-03,\n",
      "         -2.0226e-05, -1.6426e-03, -8.4239e-04, -4.0918e-04, -1.2885e-03],\n",
      "        [-9.9001e-04, -2.9323e-04, -1.2419e-03, -2.6412e-03, -3.1625e-05,\n",
      "         -5.8679e-04, -9.9623e-04, -1.4106e-03, -4.7810e-04, -2.4221e-04,\n",
      "         -1.1222e-03, -1.5644e-03, -1.2789e-04, -1.2335e-03, -1.4134e-03,\n",
      "         -5.1554e-05, -2.3423e-03, -2.3341e-04, -2.7304e-04, -5.2258e-04],\n",
      "        [ 2.2553e-04,  3.1582e-04,  4.4257e-04,  1.7225e-03,  6.8645e-05,\n",
      "          3.7416e-04,  5.9759e-04,  9.2867e-04,  2.5818e-04,  1.4457e-04,\n",
      "          7.8092e-04,  5.7913e-04,  3.2398e-06,  8.6583e-04,  4.4926e-04,\n",
      "          1.7553e-04,  1.6458e-03,  5.5772e-05,  2.3485e-04,  2.4242e-04],\n",
      "        [-3.8283e-03, -1.3901e-03, -3.9488e-03, -2.1061e-03, -1.4651e-04,\n",
      "         -5.2312e-04, -3.4910e-03, -2.1769e-03, -9.9505e-04, -1.3121e-03,\n",
      "         -1.9611e-03, -5.1454e-03, -9.2089e-04, -1.4517e-03, -5.0880e-03,\n",
      "         -4.1624e-04, -2.1534e-03, -1.6336e-03, -1.7493e-03, -1.0738e-03],\n",
      "        [-9.1781e-04, -9.0088e-04, -6.0746e-04, -4.6488e-04, -8.8560e-05,\n",
      "         -3.2820e-05, -1.1780e-03, -4.3867e-04, -4.6593e-04, -6.5063e-04,\n",
      "         -1.9475e-04, -1.8712e-03, -2.5975e-04, -4.9852e-04, -1.7095e-03,\n",
      "         -3.8571e-04, -1.1192e-03, -4.9085e-04, -6.7049e-04, -3.6880e-04],\n",
      "        [-1.7913e-03, -7.2534e-04, -1.6606e-03, -2.4375e-04, -5.6755e-05,\n",
      "         -1.6079e-05, -1.3237e-03, -2.7619e-04, -5.3459e-04, -8.1566e-04,\n",
      "         -1.7741e-04, -1.9832e-03, -3.6497e-04, -4.9093e-04, -2.3121e-03,\n",
      "         -2.8463e-04, -4.6526e-04, -7.4871e-04, -8.8185e-04, -5.5702e-04],\n",
      "        [-1.9805e-03, -1.6790e-04, -1.7418e-03, -6.5990e-04, -1.2608e-05,\n",
      "         -2.7575e-05, -6.4015e-04, -3.1900e-04, -7.4339e-04, -3.2746e-04,\n",
      "         -2.9878e-04, -1.5580e-03, -6.3275e-04, -5.4845e-04, -2.4237e-03,\n",
      "         -2.8833e-05, -9.8378e-04, -5.5558e-04, -3.8919e-04, -8.2414e-04],\n",
      "        [ 6.8706e-06, -1.0739e-05,  2.4450e-05, -6.1010e-06, -3.6588e-06,\n",
      "         -4.3608e-05, -2.1485e-06, -6.2428e-05,  1.0455e-05, -6.0020e-06,\n",
      "         -8.9916e-05, -7.9311e-06,  0.0000e+00, -5.8689e-06,  3.5821e-05,\n",
      "         -4.8666e-06,  5.7086e-05,  5.7075e-07, -1.3420e-05,  6.7712e-06],\n",
      "        [-5.9904e-03, -2.4487e-03, -5.2607e-03, -3.9010e-03, -3.2711e-04,\n",
      "         -1.2394e-03, -5.3100e-03, -4.3230e-03, -1.8648e-03, -2.2560e-03,\n",
      "         -4.4001e-03, -7.3652e-03, -1.5450e-03, -2.3775e-03, -6.6429e-03,\n",
      "         -1.1124e-03, -3.7252e-03, -2.3168e-03, -3.1366e-03, -2.0532e-03],\n",
      "        [-1.1342e-03,  8.4186e-06, -1.2467e-03, -2.5267e-03,  8.7168e-06,\n",
      "         -2.2347e-04,  8.7492e-05, -2.1693e-04, -8.8095e-04, -9.5363e-07,\n",
      "          1.1775e-04, -4.0274e-04, -1.1898e-04, -1.4897e-03, -1.4851e-03,\n",
      "          4.0137e-06, -2.7387e-03, -2.8881e-05,  1.7576e-06, -9.3727e-04],\n",
      "        [-1.0053e-02, -2.3998e-03, -1.0078e-02, -1.2551e-02, -2.7122e-04,\n",
      "         -1.9760e-03, -6.0438e-03, -5.5405e-03, -4.5784e-03, -2.5690e-03,\n",
      "         -4.4480e-03, -1.1852e-02, -2.6173e-03, -6.9019e-03, -1.4477e-02,\n",
      "         -1.0138e-03, -1.5537e-02, -2.8041e-03, -3.1347e-03, -4.9317e-03],\n",
      "        [ 8.5584e-05, -1.1113e-04,  7.8426e-05,  5.4664e-04,  5.4250e-06,\n",
      "          6.2375e-05, -2.8070e-04,  1.9804e-04, -9.1599e-05, -1.5918e-04,\n",
      "          1.6802e-04, -6.4156e-04, -2.4295e-04,  3.5960e-04, -8.2916e-04,\n",
      "          5.0554e-05,  6.4257e-04, -2.2544e-04, -1.0864e-04, -1.1395e-04],\n",
      "        [-1.4117e-03, -5.6866e-04, -2.3329e-03, -9.9334e-03, -1.7894e-04,\n",
      "         -2.7497e-03, -2.2528e-03, -5.8971e-03, -1.4970e-03, -1.8801e-04,\n",
      "         -5.1198e-03, -2.8650e-03, -3.0720e-05, -5.2725e-03, -2.2815e-03,\n",
      "         -1.8059e-04, -9.9570e-03, -8.0713e-05, -2.5506e-04, -1.4769e-03],\n",
      "        [-2.7904e-05, -5.1750e-04, -5.2678e-05, -8.0551e-04, -1.1365e-04,\n",
      "         -4.2344e-04, -1.1938e-03, -1.3736e-03,  0.0000e+00, -2.6915e-04,\n",
      "         -1.6344e-03, -8.9176e-04, -2.6083e-06, -2.7375e-04, -1.1919e-04,\n",
      "         -2.4302e-04, -3.6946e-04, -8.0931e-05, -4.4752e-04,  5.0848e-08],\n",
      "        [-9.7164e-03, -2.1119e-03, -1.0048e-02, -1.2688e-02, -2.4897e-04,\n",
      "         -1.8488e-03, -5.1403e-03, -4.8376e-03, -4.8708e-03, -2.1567e-03,\n",
      "         -3.5501e-03, -1.0175e-02, -2.2492e-03, -7.4745e-03, -1.3933e-02,\n",
      "         -8.4062e-04, -1.3643e-02, -2.5593e-03, -2.7808e-03, -5.2842e-03],\n",
      "        [ 1.2031e-04,  2.0893e-04,  1.7425e-04,  6.9602e-04,  2.6402e-05,\n",
      "          5.6286e-05,  3.2287e-04,  2.0796e-04,  4.9987e-05,  1.9944e-04,\n",
      "          2.2637e-04,  2.7574e-04,  5.3149e-05,  1.8188e-04,  2.0741e-04,\n",
      "          1.4526e-04,  8.6082e-04,  1.9983e-05,  1.1752e-04,  1.0550e-04],\n",
      "        [-5.2291e-04, -1.1705e-04, -5.2981e-04, -4.2628e-04, -3.7368e-06,\n",
      "         -5.9898e-06, -3.2825e-04, -6.9130e-05, -3.6209e-04, -1.9596e-04,\n",
      "         -4.6354e-06, -9.2417e-04, -2.6012e-04, -2.9018e-04, -1.2853e-03,\n",
      "         -4.8230e-05, -4.7506e-04, -2.0289e-04, -1.9502e-04, -4.1349e-04],\n",
      "        [-1.4976e-03, -1.3259e-04, -1.3912e-03, -6.0961e-04, -8.0473e-07,\n",
      "         -1.1593e-05, -4.0555e-04, -1.1796e-04, -5.1793e-04, -2.1475e-04,\n",
      "         -1.8950e-06, -1.0292e-03, -9.2305e-05, -8.6099e-04, -1.8678e-03,\n",
      "         -8.9103e-06, -5.3450e-04, -2.5031e-04, -5.9024e-05, -6.9422e-04]]), 'exp_avg_sq': tensor([[4.8493e-10, 1.4766e-11, 3.3914e-09, 1.0402e-07, 2.4209e-11, 1.1463e-08,\n",
      "         3.7827e-09, 6.2676e-08, 3.7200e-10, 2.1490e-14, 5.3048e-08, 8.5359e-09,\n",
      "         1.6058e-14, 2.7435e-08, 3.6739e-09, 3.8102e-12, 1.3490e-07, 0.0000e+00,\n",
      "         1.4351e-13, 1.2634e-10],\n",
      "        [5.1192e-06, 4.3427e-07, 5.0888e-06, 4.0617e-06, 6.9464e-09, 1.1299e-07,\n",
      "         2.2740e-06, 1.2751e-06, 8.7749e-07, 4.2267e-07, 1.0060e-06, 6.9796e-06,\n",
      "         3.7667e-07, 1.3399e-06, 1.0213e-05, 9.4339e-08, 5.7562e-06, 5.4131e-07,\n",
      "         7.3528e-07, 1.0408e-06],\n",
      "        [4.4928e-07, 2.6278e-10, 4.2970e-07, 6.8040e-07, 6.4384e-12, 1.1866e-08,\n",
      "         1.1811e-08, 6.7803e-08, 1.2154e-07, 4.0131e-09, 3.4314e-08, 2.8826e-07,\n",
      "         3.5155e-08, 2.4601e-07, 8.8625e-07, 4.0408e-11, 9.7315e-07, 1.8391e-08,\n",
      "         5.0871e-09, 1.3847e-07],\n",
      "        [2.8114e-07, 7.7588e-09, 2.5710e-07, 9.9523e-08, 3.3964e-11, 7.7547e-11,\n",
      "         4.0358e-08, 3.9362e-09, 3.7431e-08, 1.4095e-08, 4.9056e-10, 2.3687e-07,\n",
      "         2.2647e-08, 3.6361e-08, 4.6888e-07, 1.2024e-09, 1.8646e-07, 2.6334e-08,\n",
      "         2.2803e-08, 4.4066e-08],\n",
      "        [2.1736e-06, 1.6411e-07, 2.3187e-06, 3.7095e-06, 2.7795e-09, 1.2957e-07,\n",
      "         8.4601e-07, 7.8873e-07, 6.0770e-07, 1.4805e-07, 5.4078e-07, 2.8817e-06,\n",
      "         1.3462e-07, 1.4566e-06, 5.0953e-06, 3.5054e-08, 4.5604e-06, 1.9056e-07,\n",
      "         2.7343e-07, 7.0651e-07],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00],\n",
      "        [1.4214e-09, 1.2401e-09, 2.0485e-09, 3.1547e-08, 3.3643e-11, 1.4416e-09,\n",
      "         2.6379e-09, 2.7286e-09, 7.1564e-10, 5.0812e-10, 4.5055e-10, 2.8312e-09,\n",
      "         1.7792e-11, 1.0758e-08, 2.3268e-09, 5.8643e-10, 4.2236e-08, 1.8687e-10,\n",
      "         1.1549e-09, 8.2649e-10],\n",
      "        [1.6355e-06, 1.4677e-07, 1.6744e-06, 1.0713e-06, 8.5964e-10, 6.4820e-09,\n",
      "         5.6515e-07, 4.2985e-08, 2.4134e-07, 1.6265e-07, 7.4349e-09, 1.7491e-06,\n",
      "         1.2356e-07, 3.1726e-07, 2.7124e-06, 3.0855e-08, 1.3553e-06, 2.1844e-07,\n",
      "         2.8151e-07, 2.7385e-07],\n",
      "        [1.3108e-06, 8.9256e-08, 1.3886e-06, 2.2285e-06, 1.4156e-09, 5.7283e-08,\n",
      "         4.0856e-07, 3.7088e-07, 3.1197e-07, 7.4833e-08, 2.3785e-07, 1.4099e-06,\n",
      "         6.7005e-08, 8.0789e-07, 2.4516e-06, 1.9935e-08, 2.9627e-06, 1.0154e-07,\n",
      "         1.3879e-07, 3.5785e-07],\n",
      "        [1.7537e-07, 6.9305e-08, 1.6754e-07, 5.8269e-08, 1.0996e-09, 9.5044e-09,\n",
      "         2.4080e-07, 6.7792e-08, 1.4832e-08, 5.9219e-08, 1.0029e-07, 3.1936e-07,\n",
      "         1.5290e-08, 8.8852e-09, 3.5085e-07, 1.3027e-08, 9.2893e-08, 7.1161e-08,\n",
      "         1.1079e-07, 2.1015e-08],\n",
      "        [4.2798e-09, 2.6413e-09, 2.9835e-09, 1.7191e-09, 1.9751e-11, 1.7534e-11,\n",
      "         1.0437e-09, 5.8557e-11, 9.8221e-10, 1.1105e-09, 5.0507e-11, 5.6458e-09,\n",
      "         3.5605e-10, 5.6977e-10, 9.8328e-09, 9.0296e-10, 1.1753e-10, 5.4143e-10,\n",
      "         3.4217e-09, 8.5109e-10],\n",
      "        [4.8617e-07, 8.4592e-09, 4.7952e-07, 2.9313e-07, 5.1820e-12, 4.3510e-09,\n",
      "         3.9982e-08, 1.1302e-08, 8.8709e-08, 1.3642e-08, 8.6451e-10, 3.1693e-07,\n",
      "         2.9607e-08, 1.6151e-07, 8.1885e-07, 3.9791e-10, 5.2968e-07, 4.0189e-08,\n",
      "         2.5534e-08, 1.0552e-07],\n",
      "        [7.7650e-08, 5.6506e-09, 7.0960e-08, 1.2748e-07, 4.5531e-11, 3.1724e-09,\n",
      "         1.9519e-08, 1.8374e-08, 1.7351e-08, 3.8450e-09, 6.0996e-09, 6.8351e-08,\n",
      "         4.9074e-09, 4.2205e-08, 1.3955e-07, 1.3581e-09, 1.8538e-07, 5.6933e-09,\n",
      "         7.0426e-09, 2.1104e-08],\n",
      "        [8.3383e-09, 1.6394e-10, 8.0025e-09, 3.2269e-10, 2.8243e-13, 4.3654e-11,\n",
      "         5.0317e-10, 2.4596e-10, 2.7358e-09, 1.4050e-11, 1.4626e-12, 3.1939e-09,\n",
      "         1.1205e-10, 5.4843e-09, 1.2844e-08, 1.0486e-13, 6.2568e-10, 3.7469e-10,\n",
      "         5.5029e-10, 3.1216e-09],\n",
      "        [5.4779e-08, 9.9387e-08, 5.5596e-08, 5.2012e-08, 1.4716e-09, 4.3250e-09,\n",
      "         3.1115e-07, 7.1595e-08, 7.0419e-10, 5.5897e-08, 5.8551e-08, 3.3956e-07,\n",
      "         3.0970e-09, 3.6136e-09, 1.2016e-07, 2.6805e-08, 1.8342e-08, 2.9556e-08,\n",
      "         1.2563e-07, 8.4138e-10],\n",
      "        [2.6698e-08, 1.3699e-11, 1.7487e-08, 5.1326e-08, 1.8039e-13, 6.6496e-10,\n",
      "         1.6947e-10, 1.2915e-09, 1.7841e-08, 1.2751e-10, 8.2080e-11, 1.8966e-08,\n",
      "         6.4842e-09, 1.9478e-08, 8.4530e-08, 3.8683e-12, 7.7272e-08, 7.9572e-10,\n",
      "         1.2159e-10, 2.1504e-08],\n",
      "        [1.1907e-08, 3.6314e-08, 8.9646e-09, 1.4667e-09, 6.8862e-10, 1.3972e-09,\n",
      "         9.3027e-08, 1.7313e-08, 2.2352e-10, 1.6251e-08, 1.7080e-08, 7.5694e-08,\n",
      "         7.3304e-10, 1.0016e-09, 2.0325e-08, 1.0991e-08, 3.9560e-09, 9.3096e-09,\n",
      "         3.9307e-08, 2.1146e-10],\n",
      "        [3.2752e-06, 2.1974e-07, 3.5377e-06, 5.8492e-06, 3.6953e-09, 1.4720e-07,\n",
      "         1.0567e-06, 9.4855e-07, 8.8065e-07, 1.9749e-07, 5.9436e-07, 3.8195e-06,\n",
      "         1.9953e-07, 2.0861e-06, 6.9742e-06, 5.0436e-08, 6.8872e-06, 2.6189e-07,\n",
      "         3.8481e-07, 1.0162e-06],\n",
      "        [1.6724e-06, 1.5961e-07, 1.4798e-06, 6.1096e-08, 5.8101e-10, 6.8467e-10,\n",
      "         6.4454e-07, 1.0940e-08, 1.4187e-07, 2.3647e-07, 8.9925e-09, 1.7304e-06,\n",
      "         1.1381e-07, 1.3649e-07, 2.2605e-06, 2.6680e-08, 2.9104e-07, 2.7985e-07,\n",
      "         3.8894e-07, 1.8212e-07],\n",
      "        [1.6400e-15, 3.6911e-09, 1.3665e-11, 1.1713e-08, 4.5160e-10, 1.9406e-09,\n",
      "         2.9531e-08, 4.2337e-08, 0.0000e+00, 3.1944e-10, 6.5544e-08, 1.1582e-08,\n",
      "         0.0000e+00, 7.7681e-10, 1.3921e-11, 1.3846e-09, 1.7208e-09, 3.4469e-11,\n",
      "         5.4275e-10, 1.8374e-12],\n",
      "        [1.0451e-07, 1.9774e-08, 1.0277e-07, 3.8958e-08, 3.6821e-10, 5.8819e-09,\n",
      "         9.9274e-08, 4.8101e-08, 5.5522e-09, 1.1993e-08, 5.2030e-08, 1.9294e-07,\n",
      "         5.2183e-09, 1.9377e-08, 1.7302e-07, 2.9763e-09, 3.0180e-08, 2.2882e-08,\n",
      "         3.3471e-08, 7.2706e-09],\n",
      "        [2.0351e-06, 1.7922e-07, 2.1826e-06, 4.1689e-06, 3.6201e-09, 1.4369e-07,\n",
      "         8.5493e-07, 8.7123e-07, 4.2351e-07, 1.3977e-07, 6.1650e-07, 2.6374e-06,\n",
      "         1.2525e-07, 1.2431e-06, 3.9687e-06, 4.1094e-08, 5.2536e-06, 1.9663e-07,\n",
      "         2.8463e-07, 5.2071e-07],\n",
      "        [1.8281e-07, 2.0855e-11, 1.8254e-07, 1.1093e-08, 9.9662e-13, 3.0818e-11,\n",
      "         2.8226e-09, 1.1594e-10, 3.4381e-08, 4.1223e-09, 0.0000e+00, 8.7816e-08,\n",
      "         3.0328e-08, 7.3045e-09, 2.5918e-07, 4.6767e-11, 7.1934e-08, 1.9196e-08,\n",
      "         4.8610e-09, 4.3248e-08],\n",
      "        [3.4185e-08, 6.5824e-09, 4.8972e-08, 2.0955e-07, 8.9574e-11, 8.6014e-09,\n",
      "         3.1106e-08, 4.2533e-08, 1.0653e-08, 2.9919e-09, 2.7204e-08, 6.4645e-08,\n",
      "         5.4713e-10, 5.2767e-08, 7.1969e-08, 1.3867e-09, 1.6961e-07, 2.6408e-09,\n",
      "         5.7679e-09, 1.2710e-08],\n",
      "        [2.7395e-09, 6.2793e-09, 7.2942e-09, 9.9247e-08, 2.2751e-10, 4.2048e-09,\n",
      "         2.0426e-08, 3.0351e-08, 2.6786e-09, 1.4724e-09, 2.7470e-08, 1.6720e-08,\n",
      "         5.9370e-12, 2.5142e-08, 7.6530e-09, 2.0538e-09, 9.4567e-08, 2.9773e-10,\n",
      "         4.3845e-09, 2.4857e-09],\n",
      "        [2.9249e-07, 3.9208e-08, 3.0815e-07, 8.8708e-08, 5.4024e-10, 5.9026e-09,\n",
      "         2.3956e-07, 9.3864e-08, 2.0036e-08, 3.5798e-08, 7.8835e-08, 5.1829e-07,\n",
      "         1.8426e-08, 4.6982e-08, 5.1331e-07, 4.4453e-09, 9.8358e-08, 5.2991e-08,\n",
      "         6.2120e-08, 2.3454e-08],\n",
      "        [2.1055e-08, 1.7047e-08, 9.1580e-09, 5.0387e-09, 2.1116e-10, 5.4416e-11,\n",
      "         2.9171e-08, 5.2063e-09, 5.6176e-09, 9.0934e-09, 1.2380e-09, 7.0766e-08,\n",
      "         2.2217e-09, 5.9377e-09, 6.5871e-08, 4.2903e-09, 2.9229e-08, 5.8538e-09,\n",
      "         1.2767e-08, 3.5900e-09],\n",
      "        [7.3103e-08, 1.6026e-08, 5.9389e-08, 1.6135e-09, 1.4234e-10, 3.1241e-11,\n",
      "         4.7077e-08, 1.8943e-09, 7.7068e-09, 1.6695e-08, 1.3044e-09, 9.4004e-08,\n",
      "         4.9088e-09, 1.0337e-08, 1.1463e-07, 3.3993e-09, 6.1147e-09, 1.6251e-08,\n",
      "         3.0528e-08, 8.9262e-09],\n",
      "        [1.0880e-07, 1.7120e-09, 8.1429e-08, 1.3011e-08, 4.0014e-11, 7.7170e-11,\n",
      "         1.1407e-08, 3.3436e-09, 1.4956e-08, 3.0888e-09, 4.0786e-09, 6.2268e-08,\n",
      "         1.2282e-08, 7.2235e-09, 1.5438e-07, 4.3029e-10, 3.0060e-08, 8.9439e-09,\n",
      "         5.3467e-09, 1.7360e-08],\n",
      "        [3.7757e-11, 1.3893e-10, 6.3342e-10, 4.8446e-08, 2.9543e-11, 6.0337e-09,\n",
      "         2.8789e-09, 2.9101e-08, 1.0632e-10, 9.3150e-12, 3.5215e-08, 3.2579e-09,\n",
      "         0.0000e+00, 8.5659e-09, 6.4319e-10, 3.8376e-11, 4.8476e-08, 3.2885e-12,\n",
      "         7.8658e-11, 1.0811e-10],\n",
      "        [7.5645e-07, 1.6321e-07, 5.6659e-07, 3.0902e-07, 2.8815e-09, 3.2342e-08,\n",
      "         6.5111e-07, 3.7700e-07, 7.1544e-08, 1.2610e-07, 4.0723e-07, 1.1323e-06,\n",
      "         6.0539e-08, 1.3360e-07, 9.0728e-07, 3.7063e-08, 3.1072e-07, 1.3619e-07,\n",
      "         2.4812e-07, 8.6639e-08],\n",
      "        [3.8866e-08, 1.5579e-11, 4.4942e-08, 2.3364e-07, 1.4695e-11, 4.7782e-09,\n",
      "         2.7759e-09, 2.1002e-08, 2.2776e-08, 1.8205e-11, 1.8242e-08, 1.0793e-08,\n",
      "         6.1237e-10, 7.1376e-08, 6.5174e-08, 5.1359e-12, 2.6639e-07, 1.2814e-10,\n",
      "         1.8117e-11, 2.6329e-08],\n",
      "        [2.2120e-06, 1.5781e-07, 2.1726e-06, 3.2178e-06, 1.9915e-09, 8.4424e-08,\n",
      "         8.7002e-07, 6.7390e-07, 4.2986e-07, 1.5905e-07, 4.6757e-07, 3.0217e-06,\n",
      "         1.4733e-07, 9.7401e-07, 4.3328e-06, 3.2287e-08, 4.9769e-06, 1.9888e-07,\n",
      "         2.8417e-07, 4.9363e-07],\n",
      "        [2.0091e-07, 2.9119e-08, 2.0456e-07, 1.8722e-07, 2.4519e-10, 5.6879e-10,\n",
      "         1.1274e-07, 2.3764e-08, 3.7946e-08, 2.3554e-08, 1.7150e-08, 3.5553e-07,\n",
      "         1.9620e-08, 6.2792e-08, 5.0624e-07, 6.6542e-09, 3.4823e-07, 2.1650e-08,\n",
      "         4.5221e-08, 4.6120e-08],\n",
      "        [4.7402e-08, 9.6433e-09, 1.2525e-07, 1.9710e-06, 8.8015e-10, 1.5035e-07,\n",
      "         1.1891e-07, 6.9347e-07, 5.3944e-08, 1.2084e-09, 5.5314e-07, 1.7919e-07,\n",
      "         6.9955e-11, 5.6478e-07, 1.1473e-07, 1.1732e-09, 1.9901e-06, 2.4331e-10,\n",
      "         3.4220e-09, 5.4409e-08],\n",
      "        [5.9555e-11, 8.0021e-09, 1.0940e-10, 1.5549e-08, 3.7228e-10, 3.9338e-09,\n",
      "         3.5282e-08, 3.9175e-08, 0.0000e+00, 2.3612e-09, 5.6401e-08, 1.9674e-08,\n",
      "         1.2849e-12, 2.2727e-09, 6.8784e-10, 1.9924e-09, 3.6426e-09, 2.7094e-10,\n",
      "         6.4852e-09, 3.2027e-15],\n",
      "        [1.8565e-06, 9.0785e-08, 1.9797e-06, 3.1563e-06, 1.5871e-09, 6.7322e-08,\n",
      "         5.1962e-07, 4.5672e-07, 5.1170e-07, 9.6165e-08, 2.6233e-07, 2.0175e-06,\n",
      "         1.0105e-07, 1.1597e-06, 3.9341e-06, 1.7555e-08, 3.6471e-06, 1.3092e-07,\n",
      "         1.6316e-07, 5.9783e-07],\n",
      "        [2.9812e-07, 2.3197e-08, 3.0091e-07, 2.8948e-07, 1.8135e-10, 1.2565e-09,\n",
      "         8.2446e-08, 2.5628e-08, 5.9832e-08, 1.6242e-08, 1.9259e-08, 2.8591e-07,\n",
      "         1.6709e-08, 1.2545e-07, 5.5323e-07, 5.3876e-09, 5.1752e-07, 2.0855e-08,\n",
      "         3.3599e-08, 7.0355e-08],\n",
      "        [6.3319e-08, 5.3860e-10, 5.4737e-08, 2.3161e-08, 1.7815e-12, 1.6085e-11,\n",
      "         4.9608e-09, 8.1298e-10, 1.4907e-08, 1.5792e-09, 2.8265e-11, 5.8645e-08,\n",
      "         8.1070e-09, 8.5156e-09, 1.6071e-07, 1.6648e-10, 4.4461e-08, 4.3683e-09,\n",
      "         2.1398e-09, 1.6811e-08],\n",
      "        [5.7436e-08, 1.4534e-09, 5.4393e-08, 1.1161e-08, 1.1805e-12, 1.5906e-11,\n",
      "         6.7308e-09, 5.1520e-10, 1.2058e-08, 2.0711e-09, 3.5632e-13, 3.2027e-08,\n",
      "         3.0738e-10, 2.7118e-08, 9.5458e-08, 8.5241e-12, 9.1817e-09, 2.0007e-09,\n",
      "         2.5176e-10, 1.5927e-08]])}, 3: {'step': tensor(21.), 'exp_avg': tensor([-2.2204e-03, -2.7815e-02,  5.8526e-03, -4.2955e-03, -1.9702e-02,\n",
      "         0.0000e+00,  3.8910e-04, -1.1854e-02, -1.4118e-02, -5.3972e-03,\n",
      "         2.7662e-04, -5.6609e-03, -1.8200e-03,  2.9830e-04, -5.4680e-03,\n",
      "         1.0071e-03, -2.3810e-03, -2.2899e-02, -1.0938e-02, -1.4817e-03,\n",
      "        -3.3338e-03, -1.9356e-02, -1.9730e-03, -3.0491e-03,  1.6202e-03,\n",
      "        -7.1319e-03, -2.2886e-03, -2.4894e-03, -1.9915e-03, -3.2842e-05,\n",
      "        -1.1206e-02, -1.2110e-03, -1.8671e-02, -1.6876e-04, -9.1034e-03,\n",
      "        -1.9324e-03, -1.6674e-02,  5.8447e-04, -1.0325e-03, -1.6556e-03]), 'exp_avg_sq': tensor([1.1686e-07, 1.5177e-05, 9.0296e-07, 3.8237e-07, 7.5987e-06, 0.0000e+00,\n",
      "        1.3031e-08, 2.7418e-06, 3.9181e-06, 5.8375e-07, 7.6140e-09, 6.2154e-07,\n",
      "        1.8456e-07, 7.8077e-09, 5.9061e-07, 3.7156e-08, 1.2412e-07, 1.0116e-05,\n",
      "        2.3544e-06, 5.7375e-08, 3.7949e-07, 7.3065e-06, 1.0097e-07, 2.2503e-07,\n",
      "        9.9820e-08, 9.8996e-07, 1.0536e-07, 1.3742e-07, 9.8891e-08, 4.9488e-08,\n",
      "        2.5156e-06, 9.9959e-08, 7.4302e-06, 6.3592e-07, 1.6669e-06, 8.1241e-08,\n",
      "        5.4034e-06, 6.7828e-07, 9.0323e-08, 7.5699e-08])}, 4: {'step': tensor(21.), 'exp_avg': tensor([[ 1.8348e-05,  1.2364e-03,  2.2454e-04,  ...,  6.0450e-04,\n",
      "          4.1857e-04,  2.3870e-05],\n",
      "        [-6.0479e-04, -7.5470e-03, -8.2113e-03,  ..., -3.7845e-03,\n",
      "         -2.3634e-03, -3.0508e-04],\n",
      "        [-5.9566e-07, -7.5111e-07, -4.0362e-05,  ..., -1.1784e-06,\n",
      "         -9.7141e-07,  0.0000e+00],\n",
      "        ...,\n",
      "        [-1.4669e-04, -2.0227e-03, -1.7724e-03,  ..., -7.8271e-04,\n",
      "         -4.7318e-04, -8.6972e-05],\n",
      "        [-1.4353e-04, -1.0074e-03, -6.1299e-04,  ..., -1.7042e-04,\n",
      "         -1.3149e-05, -1.9551e-05],\n",
      "        [ 1.1259e-06,  3.4043e-04,  8.8280e-04,  ...,  3.9412e-04,\n",
      "          2.4386e-04,  4.2191e-06]]), 'exp_avg_sq': tensor([[9.6732e-11, 1.4614e-07, 1.2236e-08,  ..., 5.4627e-08, 2.5813e-08,\n",
      "         8.2798e-11],\n",
      "        [8.3050e-09, 1.1528e-06, 1.3607e-06,  ..., 3.3444e-07, 1.3016e-07,\n",
      "         2.3836e-09],\n",
      "        [3.1121e-13, 3.6370e-12, 6.6296e-10,  ..., 3.0865e-13, 2.9489e-13,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.3826e-09, 1.4140e-07, 3.0975e-07,  ..., 6.2289e-08, 2.0613e-08,\n",
      "         4.8899e-10],\n",
      "        [1.4653e-09, 8.7468e-08, 1.2636e-07,  ..., 4.4486e-08, 1.8268e-08,\n",
      "         1.1622e-10],\n",
      "        [2.3745e-12, 1.6149e-08, 1.4433e-07,  ..., 3.5192e-08, 1.1097e-08,\n",
      "         1.1997e-11]])}, 5: {'step': tensor(21.), 'exp_avg': tensor([ 2.9266e-03, -2.3728e-02, -3.7796e-05, -7.0676e-02, -3.3629e-02,\n",
      "        -1.1086e-02, -1.2209e-04, -4.9647e-02, -3.9364e-02, -1.0619e-02,\n",
      "         4.8311e-03,  4.0410e-04, -1.4365e-04,  0.0000e+00,  4.5489e-04,\n",
      "         2.9016e-04, -8.8373e-03, -3.2826e-02,  4.3048e-03,  2.7577e-05,\n",
      "        -9.7008e-07,  3.7590e-03,  2.4426e-03, -2.1295e-03,  1.1003e-03,\n",
      "        -3.2666e-05, -2.9567e-02,  7.2811e-03, -1.3237e-02,  1.3246e-03,\n",
      "         1.7330e-02, -1.4681e-02,  3.6440e-03,  3.6140e-05,  3.3391e-04,\n",
      "        -5.6286e-03, -2.9665e-02, -5.1096e-03, -3.0397e-03,  1.2860e-03]), 'exp_avg_sq': tensor([8.6141e-07, 1.1691e-05, 4.9314e-10, 1.0880e-04, 2.2339e-05, 2.7469e-06,\n",
      "        7.1543e-09, 5.0412e-05, 3.0940e-05, 2.2217e-06, 2.7227e-06, 1.6811e-08,\n",
      "        7.8838e-10, 0.0000e+00, 1.1461e-07, 5.2816e-09, 1.7743e-06, 2.1180e-05,\n",
      "        2.9747e-06, 7.6797e-10, 1.4377e-12, 1.6784e-06, 2.3198e-07, 1.2615e-07,\n",
      "        1.5348e-07, 8.7847e-09, 1.6864e-05, 1.8216e-06, 3.8267e-06, 2.7668e-07,\n",
      "        6.8990e-06, 4.3810e-06, 1.3348e-06, 1.2427e-09, 4.5980e-08, 1.3048e-06,\n",
      "        1.8831e-05, 1.5210e-06, 1.0371e-06, 2.5320e-07])}, 6: {'step': tensor(21.), 'exp_avg': tensor([[ 3.5640e-05,  1.0853e-04,  1.7230e-06,  2.4480e-04,  4.2427e-04,\n",
      "          5.7775e-07,  3.9735e-06,  3.3811e-04,  5.3048e-05,  2.6335e-05,\n",
      "          2.8264e-04,  5.8200e-07,  0.0000e+00,  0.0000e+00,  1.0089e-05,\n",
      "          1.8622e-06,  3.8073e-05,  4.3666e-04,  4.4061e-04,  0.0000e+00,\n",
      "          0.0000e+00,  2.4088e-04,  2.1100e-04,  9.9440e-05,  7.7617e-07,\n",
      "          4.2129e-05,  7.7201e-05,  3.9364e-05,  3.3441e-04,  3.5358e-05,\n",
      "          3.2989e-04,  1.1494e-04,  1.6399e-04,  4.8661e-08,  1.5889e-04,\n",
      "          3.4671e-04,  1.4672e-04,  2.7956e-04,  6.5412e-04,  2.4879e-05],\n",
      "        [-5.2188e-04, -1.5256e-02, -5.5105e-06, -2.8400e-02, -2.1408e-02,\n",
      "         -1.9099e-03, -3.3514e-05, -1.9592e-02, -1.2070e-02, -4.3767e-03,\n",
      "         -1.0062e-02, -3.1121e-05, -2.2594e-05,  0.0000e+00, -9.1953e-05,\n",
      "         -1.6810e-04, -3.5055e-03, -2.4890e-02, -9.9084e-03,  0.0000e+00,\n",
      "          0.0000e+00, -2.1278e-03, -5.1497e-03, -1.6124e-03, -6.7483e-05,\n",
      "         -3.7228e-05, -6.7029e-03, -1.3340e-03, -1.3046e-02, -2.1895e-05,\n",
      "         -6.3291e-03, -1.4771e-02, -5.1395e-04, -2.8623e-05, -6.9646e-04,\n",
      "         -2.8435e-02, -9.7017e-03, -7.6878e-03, -1.3829e-02, -4.5982e-05],\n",
      "        [-3.5404e-04, -9.9180e-03, -9.9907e-07, -1.9828e-02, -1.3017e-02,\n",
      "         -1.1412e-03, -2.1941e-05, -1.2388e-02, -7.4427e-03, -3.0939e-03,\n",
      "         -5.9311e-03, -2.1067e-05, -1.3707e-05,  0.0000e+00, -2.8186e-05,\n",
      "         -1.0125e-04, -1.9543e-03, -1.5768e-02, -6.3970e-03, -1.1033e-08,\n",
      "          0.0000e+00, -1.5313e-03, -3.3985e-03, -1.6285e-03, -7.4110e-05,\n",
      "         -2.7915e-05, -4.4821e-03, -9.7882e-04, -9.1355e-03, -1.1177e-05,\n",
      "         -4.3626e-03, -8.8584e-03, -1.6882e-04, -1.7556e-05, -5.5668e-04,\n",
      "         -1.8551e-02, -6.4422e-03, -5.4294e-03, -9.5930e-03, -2.3384e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.9130e-03, -3.3015e-02, -1.5023e-05, -6.9980e-02, -4.7142e-02,\n",
      "         -3.0998e-03, -1.2269e-04, -4.5023e-02, -2.4128e-02, -7.9708e-03,\n",
      "         -2.7196e-02, -9.5428e-05, -6.4015e-05,  0.0000e+00, -3.3216e-04,\n",
      "         -4.6974e-04, -7.4081e-03, -5.5298e-02, -2.7959e-02, -1.8188e-06,\n",
      "         -1.2197e-06, -9.4003e-03, -1.4159e-02, -6.8365e-03, -4.0478e-04,\n",
      "         -4.9667e-04, -1.4456e-02, -4.2649e-03, -3.3804e-02, -2.3209e-04,\n",
      "         -2.3025e-02, -2.9132e-02, -2.8855e-03, -6.5549e-05, -3.5601e-03,\n",
      "         -6.3723e-02, -2.0131e-02, -1.9276e-02, -4.1397e-02, -2.8978e-04],\n",
      "        [-1.9481e-04, -7.6325e-03, -4.9520e-06, -1.9824e-02, -1.2624e-02,\n",
      "         -8.0876e-04, -3.7212e-05, -1.0465e-02, -5.3761e-03, -2.4128e-03,\n",
      "         -6.1427e-03, -4.2677e-06, -2.6044e-06,  0.0000e+00, -4.6807e-05,\n",
      "         -7.1955e-05, -1.5936e-03, -1.2527e-02, -6.8377e-03,  0.0000e+00,\n",
      "          0.0000e+00, -1.8620e-03, -2.7096e-03, -2.3302e-03, -1.2370e-06,\n",
      "         -1.3993e-04, -4.3749e-03, -3.4847e-04, -8.3637e-03, -4.5508e-05,\n",
      "         -4.7704e-03, -6.1480e-03, -7.1172e-04, -1.7452e-05, -1.0114e-03,\n",
      "         -1.4248e-02, -5.2761e-03, -5.3570e-03, -1.0191e-02, -6.0275e-05],\n",
      "        [-6.4024e-04, -1.1920e-02, -7.8167e-06, -2.4550e-02, -1.6349e-02,\n",
      "         -1.4158e-03, -3.7947e-05, -1.5386e-02, -8.9840e-03, -3.0411e-03,\n",
      "         -9.3062e-03, -3.6196e-05, -2.4926e-05,  0.0000e+00, -1.0708e-04,\n",
      "         -1.7677e-04, -2.5097e-03, -1.9888e-02, -9.1345e-03, -7.2533e-07,\n",
      "         -5.8650e-07, -2.9869e-03, -4.6038e-03, -2.2693e-03, -1.5437e-04,\n",
      "         -1.6769e-04, -5.1578e-03, -1.5154e-03, -1.1817e-02, -7.7017e-05,\n",
      "         -7.7887e-03, -1.0701e-02, -8.8744e-04, -2.0587e-05, -1.0946e-03,\n",
      "         -2.2765e-02, -7.1272e-03, -6.6198e-03, -1.3928e-02, -8.4126e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.4766e-04, -3.3771e-03, -1.8117e-06, -5.7943e-03, -3.7644e-03,\n",
      "         -5.7256e-04, -6.0033e-06, -4.3144e-03, -2.7241e-03, -5.6770e-04,\n",
      "         -2.5992e-03, -1.7142e-05, -1.3687e-05,  0.0000e+00, -3.0140e-05,\n",
      "         -7.1263e-05, -7.2691e-04, -5.4588e-03, -2.0512e-03, -3.4447e-07,\n",
      "         -3.0658e-07, -5.0510e-04, -8.9703e-04, -3.5238e-04, -8.9011e-05,\n",
      "         -8.8259e-06, -1.4170e-03, -5.2334e-04, -2.9286e-03, -6.6769e-07,\n",
      "         -1.9174e-03, -2.9975e-03, -6.8428e-05, -4.6858e-06, -9.4444e-05,\n",
      "         -5.6806e-03, -1.6157e-03, -1.3001e-03, -2.9771e-03,  2.8435e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.9182e-04, -1.0935e-02, -5.1358e-06, -2.1785e-02, -1.4005e-02,\n",
      "         -1.3602e-03, -3.4641e-05, -1.3670e-02, -8.4857e-03, -2.8239e-03,\n",
      "         -7.4749e-03, -3.1720e-05, -2.4783e-05,  0.0000e+00, -6.7475e-05,\n",
      "         -1.7015e-04, -2.3460e-03, -1.7723e-02, -7.1072e-03, -6.4243e-08,\n",
      "          0.0000e+00, -2.0829e-03, -3.6771e-03, -1.8191e-03, -1.5110e-04,\n",
      "         -7.1187e-05, -4.6060e-03, -1.3511e-03, -1.0287e-02, -2.3278e-05,\n",
      "         -6.1163e-03, -9.9069e-03, -3.8077e-04, -1.3017e-05, -7.1875e-04,\n",
      "         -1.9864e-02, -6.3919e-03, -5.5490e-03, -1.1502e-02, -3.2127e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.2259e-04, -2.3225e-03, -9.4755e-07, -3.4766e-03, -2.0762e-03,\n",
      "         -5.4342e-04,  1.1434e-06, -2.5939e-03, -2.0320e-03, -2.9709e-04,\n",
      "         -1.5785e-03, -1.5444e-05, -1.4479e-05,  0.0000e+00, -1.3045e-05,\n",
      "         -5.9762e-05, -4.9934e-04, -3.6253e-03, -8.5574e-04, -5.3906e-07,\n",
      "          0.0000e+00, -2.0267e-04, -4.6097e-04,  4.4768e-05, -9.4311e-05,\n",
      "          1.5543e-05, -7.8586e-04, -4.3312e-04, -1.6752e-03,  9.5303e-06,\n",
      "         -1.1076e-03, -2.2169e-03,  4.4463e-05,  8.5501e-08,  8.4493e-05,\n",
      "         -3.7428e-03, -8.3973e-04, -5.1135e-04, -1.4085e-03,  8.1428e-06],\n",
      "        [ 4.3155e-05,  2.2371e-04,  2.3651e-07,  3.3328e-04,  3.4682e-04,\n",
      "          4.2885e-05,  2.5641e-06,  4.6435e-04,  1.9405e-04,  1.3090e-04,\n",
      "          1.7968e-04,  3.3872e-06,  1.5519e-06,  0.0000e+00,  3.3731e-06,\n",
      "          9.4535e-06,  6.0850e-05,  5.9516e-04,  2.8682e-04,  0.0000e+00,\n",
      "          0.0000e+00,  9.3944e-05,  2.1269e-04,  3.0564e-05,  1.0429e-05,\n",
      "          7.8646e-06,  1.3087e-04,  9.7695e-05,  2.5613e-04,  7.6002e-06,\n",
      "          1.4604e-04,  3.4981e-04,  5.1137e-05,  2.8113e-07,  4.7123e-05,\n",
      "          7.3828e-04,  2.2468e-04,  2.3435e-04,  3.7289e-04,  8.4061e-06],\n",
      "        [ 1.2086e-05,  2.3346e-05,  0.0000e+00,  2.0458e-04,  1.4998e-04,\n",
      "          0.0000e+00,  3.2568e-06,  8.6431e-05,  2.8520e-05,  4.1472e-06,\n",
      "          8.6443e-05,  1.4877e-06,  2.2368e-07,  0.0000e+00,  1.0752e-05,\n",
      "          4.1018e-07,  3.3142e-06,  1.5602e-04,  1.5620e-04,  0.0000e+00,\n",
      "          0.0000e+00,  9.1679e-05,  8.2339e-05,  2.3251e-05,  0.0000e+00,\n",
      "          2.2164e-05,  1.9421e-05,  2.5080e-05,  6.4972e-05,  1.6503e-05,\n",
      "          1.1672e-04,  4.5563e-05,  7.1313e-05,  7.5071e-07,  6.0344e-05,\n",
      "          1.1679e-04,  4.6159e-05,  9.9375e-05,  1.1543e-04,  1.4979e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.0671e-04, -8.3945e-03, -5.1380e-06, -1.8336e-02, -1.2445e-02,\n",
      "         -6.9553e-04, -3.1901e-05, -1.1557e-02, -5.9180e-03, -2.0694e-03,\n",
      "         -6.8656e-03, -1.9369e-05, -1.1770e-05,  0.0000e+00, -6.8598e-05,\n",
      "         -1.0309e-04, -1.8753e-03, -1.3885e-02, -7.3641e-03, -2.0242e-07,\n",
      "          0.0000e+00, -2.3601e-03, -3.5295e-03, -2.0279e-03, -5.8677e-05,\n",
      "         -1.4042e-04, -3.9145e-03, -8.7824e-04, -8.8595e-03, -6.8134e-05,\n",
      "         -5.8629e-03, -7.1648e-03, -7.6908e-04, -1.3713e-05, -1.0155e-03,\n",
      "         -1.6056e-02, -5.3590e-03, -5.1685e-03, -1.0947e-02, -8.3166e-05],\n",
      "        [-1.3848e-03, -3.0260e-02, -1.8176e-05, -6.5374e-02, -4.3278e-02,\n",
      "         -3.1507e-03, -1.0565e-04, -3.9845e-02, -2.2090e-02, -8.0173e-03,\n",
      "         -2.2891e-02, -8.1473e-05, -5.3442e-05,  0.0000e+00, -2.3699e-04,\n",
      "         -4.0789e-04, -6.5200e-03, -5.0508e-02, -2.4071e-02, -1.4556e-06,\n",
      "          0.0000e+00, -7.3265e-03, -1.1884e-02, -6.4557e-03, -2.8718e-04,\n",
      "         -3.7702e-04, -1.3680e-02, -3.3060e-03, -3.0573e-02, -1.7232e-04,\n",
      "         -1.9262e-02, -2.6405e-02, -2.0559e-03, -3.9279e-05, -3.2364e-03,\n",
      "         -5.7156e-02, -1.9236e-02, -1.7767e-02, -3.6668e-02, -2.1872e-04],\n",
      "        [-2.5133e-04, -6.8940e-03, -8.9866e-07, -1.6419e-02, -1.1244e-02,\n",
      "         -3.2835e-04, -2.9005e-05, -9.5532e-03, -4.4815e-03, -2.2918e-03,\n",
      "         -5.0046e-03,  3.2459e-06,  1.2546e-06,  0.0000e+00, -2.0810e-05,\n",
      "         -5.4528e-05, -1.5263e-03, -1.0876e-02, -6.2851e-03,  5.1977e-07,\n",
      "          0.0000e+00, -1.8723e-03, -3.1348e-03, -2.0694e-03,  4.3706e-05,\n",
      "         -8.8333e-05, -3.5181e-03, -3.0033e-04, -7.5131e-03, -4.0725e-05,\n",
      "         -4.2103e-03, -5.4973e-03, -5.6353e-04, -1.6213e-05, -9.6277e-04,\n",
      "         -1.3481e-02, -5.1778e-03, -4.8911e-03, -9.4446e-03, -6.6358e-05]]), 'exp_avg_sq': tensor([[1.2154e-09, 1.0838e-09, 2.8886e-12, 6.1119e-08, 4.4619e-08, 9.6900e-14,\n",
      "         3.5145e-11, 2.3894e-08, 3.3981e-10, 1.1232e-10, 4.0714e-08, 1.4767e-12,\n",
      "         0.0000e+00, 0.0000e+00, 6.6269e-11, 3.9478e-12, 1.3791e-10, 6.2390e-08,\n",
      "         8.6368e-08, 0.0000e+00, 0.0000e+00, 4.0194e-08, 2.5033e-08, 1.8733e-09,\n",
      "         1.6902e-12, 1.6620e-09, 5.1554e-10, 1.8085e-09, 2.6133e-08, 1.0652e-09,\n",
      "         4.8590e-08, 4.9318e-09, 2.0781e-08, 1.5703e-14, 1.1982e-08, 3.5993e-08,\n",
      "         4.4685e-09, 3.1812e-08, 1.7076e-07, 6.0027e-10],\n",
      "        [8.6198e-09, 4.7302e-06, 1.5721e-11, 1.6189e-05, 9.1895e-06, 8.0280e-08,\n",
      "         4.8299e-11, 7.7795e-06, 2.9983e-06, 4.2116e-07, 2.0127e-06, 7.4700e-11,\n",
      "         3.4119e-11, 0.0000e+00, 6.5381e-10, 1.0645e-09, 2.6358e-07, 1.2340e-05,\n",
      "         1.9477e-06, 0.0000e+00, 0.0000e+00, 1.0413e-07, 5.6220e-07, 7.0050e-08,\n",
      "         3.3720e-10, 1.1337e-10, 9.3403e-07, 4.7240e-08, 3.4957e-06, 6.4634e-11,\n",
      "         8.1462e-07, 4.3556e-06, 1.3407e-08, 5.9493e-11, 1.1699e-08, 1.6134e-05,\n",
      "         1.9211e-06, 1.2115e-06, 3.7804e-06, 2.4159e-10],\n",
      "        [4.5568e-09, 2.0069e-06, 2.8484e-13, 7.9390e-06, 3.5928e-06, 2.8323e-08,\n",
      "         1.5772e-11, 3.0278e-06, 1.0988e-06, 2.0968e-07, 7.0829e-07, 3.0473e-11,\n",
      "         7.4038e-12, 0.0000e+00, 3.0017e-11, 3.4275e-10, 8.5836e-08, 4.8576e-06,\n",
      "         8.1497e-07, 1.8595e-16, 0.0000e+00, 5.0561e-08, 2.3377e-07, 7.6166e-08,\n",
      "         5.0944e-10, 3.0015e-11, 4.3055e-07, 3.1933e-08, 1.7528e-06, 1.6239e-11,\n",
      "         3.7345e-07, 1.5372e-06, 1.3563e-09, 2.3489e-11, 7.5899e-09, 6.8422e-06,\n",
      "         8.6758e-07, 6.2906e-07, 1.9332e-06, 3.2243e-11],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.2513e-07, 2.1654e-05, 4.0616e-11, 1.0581e-04, 4.6232e-05, 2.0687e-07,\n",
      "         9.7866e-10, 4.2306e-05, 1.1965e-05, 1.2520e-06, 2.2620e-05, 9.8031e-10,\n",
      "         1.5531e-10, 0.0000e+00, 2.0347e-08, 8.5938e-09, 1.1335e-06, 6.9877e-05,\n",
      "         2.3392e-05, 5.1413e-12, 2.2728e-12, 5.1578e-06, 7.1587e-06, 9.3194e-07,\n",
      "         2.8953e-08, 3.4453e-08, 4.0742e-06, 1.1223e-06, 2.3879e-05, 1.4862e-08,\n",
      "         1.7734e-05, 1.8523e-05, 1.0851e-06, 4.8812e-10, 5.9454e-07, 8.9442e-05,\n",
      "         8.0221e-06, 8.7224e-06, 4.5265e-05, 1.7313e-08],\n",
      "        [1.6274e-09, 1.2589e-06, 7.9390e-12, 7.7560e-06, 3.1962e-06, 1.8514e-08,\n",
      "         7.1975e-11, 2.1325e-06, 6.2143e-07, 1.4324e-07, 7.6634e-07, 2.5905e-12,\n",
      "         1.1955e-12, 0.0000e+00, 2.0222e-10, 2.3950e-10, 5.5090e-08, 3.1282e-06,\n",
      "         9.8890e-07, 0.0000e+00, 0.0000e+00, 1.2625e-07, 1.5640e-07, 1.1008e-07,\n",
      "         6.6420e-13, 2.4432e-09, 3.8542e-07, 3.7452e-09, 1.3976e-06, 6.1640e-10,\n",
      "         4.8364e-07, 8.0807e-07, 4.4770e-08, 2.1751e-11, 3.3250e-08, 4.2181e-06,\n",
      "         5.8487e-07, 5.8352e-07, 2.1216e-06, 5.3750e-10],\n",
      "        [3.0183e-08, 2.7697e-06, 8.4645e-12, 1.2248e-05, 5.3558e-06, 4.1184e-08,\n",
      "         1.1380e-10, 4.7904e-06, 1.5904e-06, 1.8720e-07, 2.3632e-06, 1.3956e-10,\n",
      "         2.6311e-11, 0.0000e+00, 1.6135e-09, 1.0130e-09, 1.2947e-07, 8.4142e-06,\n",
      "         2.2944e-06, 8.0153e-13, 5.2552e-13, 4.6325e-07, 6.5929e-07, 1.0347e-07,\n",
      "         3.0261e-09, 4.1482e-09, 5.1405e-07, 1.1695e-07, 2.7967e-06, 1.8945e-09,\n",
      "         1.8464e-06, 2.3230e-06, 1.0036e-07, 4.0730e-11, 5.4416e-08, 1.0704e-05,\n",
      "         9.8596e-07, 9.6346e-07, 4.7376e-06, 1.4451e-09],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0895e-09, 2.4038e-07, 3.2656e-13, 7.0208e-07, 2.9050e-07, 7.9279e-09,\n",
      "         2.4029e-12, 3.9138e-07, 1.6043e-07, 6.7083e-09, 1.5796e-07, 4.2512e-11,\n",
      "         7.3325e-12, 0.0000e+00, 6.1625e-11, 2.0535e-10, 1.2604e-08, 6.4957e-07,\n",
      "         9.2455e-08, 1.4032e-13, 1.4359e-13, 6.9900e-09, 2.0530e-08, 2.8170e-09,\n",
      "         7.3707e-10, 2.9343e-11, 4.1991e-08, 1.1244e-08, 1.7690e-07, 1.7517e-11,\n",
      "         9.0828e-08, 1.9770e-07, 4.4299e-10, 1.6899e-12, 5.3485e-10, 6.8533e-07,\n",
      "         5.4349e-08, 3.4426e-08, 1.8270e-07, 2.1768e-11],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0752e-08, 2.3680e-06, 3.2556e-12, 9.4415e-06, 3.8780e-06, 3.8199e-08,\n",
      "         4.4131e-11, 3.8093e-06, 1.4436e-06, 1.6690e-07, 1.2252e-06, 1.0664e-10,\n",
      "         2.2412e-11, 0.0000e+00, 3.0771e-10, 1.0262e-09, 1.2040e-07, 6.3836e-06,\n",
      "         1.1007e-06, 8.6047e-15, 0.0000e+00, 1.2266e-07, 3.1919e-07, 6.6982e-08,\n",
      "         1.9453e-09, 2.0878e-10, 4.2240e-07, 6.9290e-08, 2.1010e-06, 5.5887e-11,\n",
      "         8.5624e-07, 1.9593e-06, 6.9504e-09, 1.3477e-11, 1.2180e-08, 7.9120e-06,\n",
      "         8.0395e-07, 6.2024e-07, 2.7230e-06, 4.4810e-11],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6087e-10, 1.1846e-07, 2.9743e-13, 2.6602e-07, 9.2024e-08, 7.1032e-09,\n",
      "         1.9241e-12, 1.4376e-07, 8.7023e-08, 1.9903e-09, 5.6777e-08, 3.6818e-11,\n",
      "         8.8008e-12, 0.0000e+00, 1.3385e-11, 1.7455e-10, 5.4301e-09, 2.9466e-07,\n",
      "         1.8839e-08, 3.5493e-13, 0.0000e+00, 1.2702e-09, 5.5329e-09, 5.2379e-10,\n",
      "         9.1347e-10, 1.2687e-10, 1.4928e-08, 8.0643e-09, 6.3951e-08, 7.0827e-11,\n",
      "         3.0492e-08, 1.0515e-07, 7.7147e-10, 1.5642e-12, 1.0524e-09, 2.9703e-07,\n",
      "         1.4908e-08, 7.1727e-09, 4.6915e-08, 3.1417e-11],\n",
      "        [6.4111e-10, 2.4670e-09, 1.5963e-14, 1.6055e-08, 9.1316e-09, 7.6727e-11,\n",
      "         4.7350e-12, 1.1392e-08, 1.5828e-09, 6.1688e-10, 1.0464e-08, 1.5594e-12,\n",
      "         3.8211e-13, 0.0000e+00, 2.3958e-11, 1.4311e-11, 1.7465e-10, 2.5634e-08,\n",
      "         1.9932e-08, 0.0000e+00, 0.0000e+00, 3.4298e-09, 8.1591e-09, 1.3737e-10,\n",
      "         5.8938e-11, 6.7908e-11, 6.2755e-10, 1.6124e-09, 4.7041e-09, 9.0583e-11,\n",
      "         5.3396e-09, 7.3945e-09, 2.0847e-09, 3.9690e-13, 1.3892e-09, 3.6105e-08,\n",
      "         2.6781e-09, 6.6927e-09, 2.7724e-08, 1.2519e-10],\n",
      "        [2.3141e-10, 3.7092e-10, 0.0000e+00, 2.4171e-08, 1.2721e-08, 0.0000e+00,\n",
      "         3.4802e-11, 5.3591e-09, 4.9031e-10, 1.7268e-11, 5.7114e-09, 3.6350e-12,\n",
      "         1.1627e-13, 0.0000e+00, 1.0425e-10, 3.9493e-13, 4.7948e-12, 1.7816e-08,\n",
      "         1.7212e-08, 0.0000e+00, 0.0000e+00, 7.6568e-09, 6.9314e-09, 2.9929e-10,\n",
      "         0.0000e+00, 3.5399e-10, 1.1536e-10, 8.7502e-10, 3.5162e-09, 2.2581e-10,\n",
      "         1.1727e-08, 1.9517e-09, 3.9961e-09, 2.4328e-12, 2.5416e-09, 7.7232e-09,\n",
      "         1.2750e-09, 6.8943e-09, 1.4453e-08, 2.6130e-10],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2787e-08, 1.3670e-06, 5.3491e-12, 6.8194e-06, 3.0839e-06, 1.0419e-08,\n",
      "         8.2427e-11, 2.6516e-06, 6.9510e-07, 8.4433e-08, 1.2006e-06, 3.6640e-11,\n",
      "         5.8905e-12, 0.0000e+00, 6.5608e-10, 4.1359e-10, 7.2540e-08, 4.0168e-06,\n",
      "         1.3918e-06, 6.1714e-14, 0.0000e+00, 2.7920e-07, 3.7887e-07, 8.2016e-08,\n",
      "         4.4946e-10, 2.8824e-09, 2.9711e-07, 3.9825e-08, 1.5672e-06, 1.2900e-09,\n",
      "         9.7819e-07, 1.0444e-06, 6.7415e-08, 2.4813e-11, 4.3884e-08, 5.2654e-06,\n",
      "         5.5784e-07, 5.8444e-07, 2.8364e-06, 1.2814e-09],\n",
      "        [1.1240e-07, 1.7816e-05, 5.8818e-11, 8.6331e-05, 3.7191e-05, 2.0600e-07,\n",
      "         4.4902e-10, 3.1794e-05, 9.4768e-06, 1.3225e-06, 1.2452e-05, 8.7361e-10,\n",
      "         1.1058e-10, 0.0000e+00, 4.8344e-09, 5.9344e-09, 8.8889e-07, 5.2158e-05,\n",
      "         1.4099e-05, 3.3397e-12, 0.0000e+00, 2.0699e-06, 3.7826e-06, 8.3351e-07,\n",
      "         1.2189e-08, 1.2459e-08, 3.6422e-06, 4.9294e-07, 1.8515e-05, 5.7797e-09,\n",
      "         1.0061e-05, 1.3746e-05, 3.5565e-07, 1.2417e-10, 4.0369e-07, 6.5585e-05,\n",
      "         7.1945e-06, 6.6274e-06, 3.0654e-05, 6.0929e-09],\n",
      "        [2.7658e-09, 9.7705e-07, 1.9947e-13, 5.2470e-06, 2.4946e-06, 5.2082e-09,\n",
      "         4.5131e-11, 1.7676e-06, 4.0780e-07, 1.0633e-07, 5.1776e-07, 1.4037e-11,\n",
      "         2.3444e-12, 0.0000e+00, 3.7684e-11, 1.7002e-10, 4.8053e-08, 2.3096e-06,\n",
      "         8.2810e-07, 3.4441e-13, 0.0000e+00, 1.1963e-07, 2.3359e-07, 8.6370e-08,\n",
      "         3.9915e-10, 5.8242e-10, 2.5410e-07, 2.7779e-09, 1.1157e-06, 4.1719e-10,\n",
      "         3.7308e-07, 5.9497e-07, 2.1141e-08, 2.3727e-11, 2.6935e-08, 3.5826e-06,\n",
      "         5.2696e-07, 4.8264e-07, 1.8074e-06, 4.5068e-10]])}, 7: {'step': tensor(21.), 'exp_avg': tensor([ 0.0017, -0.0583, -0.0362,  0.0000, -0.1545, -0.0349, -0.0528,  0.0000,\n",
      "        -0.0129,  0.0000,  0.0000, -0.0437,  0.0000, -0.0073,  0.0012,  0.0006,\n",
      "         0.0000, -0.0399, -0.1342, -0.0323]), 'exp_avg_sq': tensor([1.0265e-06, 6.7323e-05, 2.5831e-05, 0.0000e+00, 6.1082e-04, 2.3834e-05,\n",
      "        6.5465e-05, 0.0000e+00, 3.6057e-06, 0.0000e+00, 0.0000e+00, 3.9746e-05,\n",
      "        0.0000e+00, 1.1641e-06, 1.8446e-07, 2.4394e-07, 0.0000e+00, 3.6361e-05,\n",
      "        3.9494e-04, 2.0703e-05])}, 8: {'step': tensor(21.), 'exp_avg': tensor([[-1.3253e-05, -8.0187e-04, -1.7121e-03,  0.0000e+00, -8.8540e-03,\n",
      "         -7.3096e-04, -6.0493e-03,  0.0000e+00, -1.0821e-02,  0.0000e+00,\n",
      "          0.0000e+00, -3.3036e-03,  0.0000e+00, -2.3442e-03, -3.6279e-05,\n",
      "         -5.7103e-06,  0.0000e+00, -7.5825e-03, -3.7792e-03, -3.0413e-03],\n",
      "        [ 9.5586e-06,  1.7685e-03,  3.8828e-03,  0.0000e+00,  1.8227e-02,\n",
      "          3.5342e-04,  1.0841e-02,  0.0000e+00,  2.0319e-02,  0.0000e+00,\n",
      "          0.0000e+00,  7.0666e-03,  0.0000e+00,  4.6696e-03,  7.9366e-05,\n",
      "          3.6536e-06,  0.0000e+00,  1.5118e-02,  7.2421e-03,  5.6328e-03],\n",
      "        [-5.2281e-05, -3.3782e-03, -7.1063e-03,  0.0000e+00, -3.5680e-02,\n",
      "         -2.0968e-03, -2.4703e-02,  0.0000e+00, -4.2724e-02,  0.0000e+00,\n",
      "          0.0000e+00, -1.3528e-02,  0.0000e+00, -9.1419e-03, -1.4131e-04,\n",
      "         -2.0544e-05,  0.0000e+00, -3.1864e-02, -1.5077e-02, -1.2435e-02],\n",
      "        [ 2.4769e-05,  7.1893e-04,  1.3117e-03,  0.0000e+00,  8.3584e-03,\n",
      "          8.6220e-04,  6.7883e-03,  0.0000e+00,  9.0058e-03,  0.0000e+00,\n",
      "          0.0000e+00,  2.7174e-03,  0.0000e+00,  1.7111e-03,  3.1873e-05,\n",
      "          1.0845e-05,  0.0000e+00,  8.5243e-03,  3.6158e-03,  2.9557e-03],\n",
      "        [-5.8660e-06, -2.8790e-04, -7.1951e-04,  0.0000e+00, -2.8472e-03,\n",
      "         -9.9996e-05, -2.2251e-03,  0.0000e+00, -4.1541e-03,  0.0000e+00,\n",
      "          0.0000e+00, -1.2202e-03,  0.0000e+00, -8.8594e-04, -1.4428e-05,\n",
      "         -3.2297e-06,  0.0000e+00, -2.2846e-03, -1.1826e-03, -1.0730e-03],\n",
      "        [-6.4628e-07,  3.3922e-04,  7.5498e-04,  0.0000e+00,  3.3680e-03,\n",
      "          2.7360e-04,  2.0502e-03,  0.0000e+00,  2.4881e-03,  0.0000e+00,\n",
      "          0.0000e+00,  1.4615e-03,  0.0000e+00,  9.0023e-04,  1.2534e-05,\n",
      "         -5.7494e-07,  0.0000e+00,  2.9832e-03,  1.5429e-03,  9.4751e-04],\n",
      "        [-3.5798e-04, -1.1248e-02, -2.1286e-02,  0.0000e+00, -1.2135e-01,\n",
      "         -1.4978e-02, -9.8582e-02,  0.0000e+00, -1.4817e-01,  0.0000e+00,\n",
      "          0.0000e+00, -4.5080e-02,  0.0000e+00, -3.0832e-02, -4.7505e-04,\n",
      "         -1.5158e-04,  0.0000e+00, -1.1956e-01, -5.6433e-02, -4.7602e-02],\n",
      "        [ 2.5676e-04,  7.5860e-03,  1.4201e-02,  0.0000e+00,  8.1895e-02,\n",
      "          1.0487e-02,  6.7842e-02,  0.0000e+00,  9.9793e-02,  0.0000e+00,\n",
      "          0.0000e+00,  3.0224e-02,  0.0000e+00,  2.0552e-02,  3.2673e-04,\n",
      "          1.1014e-04,  0.0000e+00,  8.1421e-02,  3.8151e-02,  3.2441e-02],\n",
      "        [ 3.2993e-05,  1.1266e-03,  2.1885e-03,  0.0000e+00,  1.2734e-02,\n",
      "          1.5074e-03,  1.0315e-02,  0.0000e+00,  1.6016e-02,  0.0000e+00,\n",
      "          0.0000e+00,  4.6865e-03,  0.0000e+00,  3.1578e-03,  4.5669e-05,\n",
      "          1.3947e-05,  0.0000e+00,  1.2816e-02,  5.9127e-03,  5.0694e-03],\n",
      "        [-7.0891e-06,  1.1733e-05,  1.3284e-04,  0.0000e+00, -5.0207e-04,\n",
      "          7.6076e-05, -2.3163e-04,  0.0000e+00, -5.2178e-04,  0.0000e+00,\n",
      "          0.0000e+00,  2.3709e-04,  0.0000e+00,  2.0411e-04, -6.7045e-06,\n",
      "         -3.2383e-06,  0.0000e+00, -7.6814e-04,  5.2780e-05,  1.8507e-04]]), 'exp_avg_sq': tensor([[9.3260e-11, 1.4270e-08, 6.0206e-08, 0.0000e+00, 1.6689e-06, 1.1276e-08,\n",
      "         7.7835e-07, 0.0000e+00, 2.6744e-06, 0.0000e+00, 0.0000e+00, 2.2248e-07,\n",
      "         0.0000e+00, 1.0798e-07, 7.6493e-11, 2.5291e-11, 0.0000e+00, 1.2816e-06,\n",
      "         2.8181e-07, 1.8018e-07],\n",
      "        [7.7535e-11, 7.4044e-08, 3.2799e-07, 0.0000e+00, 8.1143e-06, 3.5406e-09,\n",
      "         2.9872e-06, 0.0000e+00, 1.2593e-05, 0.0000e+00, 0.0000e+00, 1.1491e-06,\n",
      "         0.0000e+00, 4.8908e-07, 3.9498e-10, 1.3030e-11, 0.0000e+00, 6.1557e-06,\n",
      "         1.2080e-06, 6.8743e-07],\n",
      "        [1.5234e-09, 2.4865e-07, 1.0140e-06, 0.0000e+00, 2.8240e-05, 8.9008e-08,\n",
      "         1.3814e-05, 0.0000e+00, 4.6220e-05, 0.0000e+00, 0.0000e+00, 3.7528e-06,\n",
      "         0.0000e+00, 1.6533e-06, 1.3434e-09, 3.2006e-10, 0.0000e+00, 2.4388e-05,\n",
      "         4.5942e-06, 3.0565e-06],\n",
      "        [3.0720e-10, 1.0737e-08, 3.5702e-08, 0.0000e+00, 1.4112e-06, 1.4632e-08,\n",
      "         1.0118e-06, 0.0000e+00, 1.9394e-06, 0.0000e+00, 0.0000e+00, 1.4837e-07,\n",
      "         0.0000e+00, 5.6701e-08, 7.9976e-11, 7.9945e-11, 0.0000e+00, 1.5854e-06,\n",
      "         2.5400e-07, 1.7144e-07],\n",
      "        [2.6427e-11, 1.9029e-09, 1.0689e-08, 0.0000e+00, 2.4468e-07, 3.0445e-10,\n",
      "         1.4580e-07, 0.0000e+00, 5.1880e-07, 0.0000e+00, 0.0000e+00, 3.1784e-08,\n",
      "         0.0000e+00, 1.6576e-08, 1.8403e-11, 9.0218e-12, 0.0000e+00, 1.9733e-07,\n",
      "         3.3403e-08, 2.4807e-08],\n",
      "        [2.4358e-12, 2.9262e-09, 1.3829e-08, 0.0000e+00, 2.3022e-07, 1.7026e-09,\n",
      "         8.5598e-08, 0.0000e+00, 1.5003e-07, 0.0000e+00, 0.0000e+00, 4.8267e-08,\n",
      "         0.0000e+00, 1.7910e-08, 8.6368e-12, 4.4238e-13, 0.0000e+00, 1.7787e-07,\n",
      "         5.0294e-08, 2.0278e-08],\n",
      "        [6.3492e-08, 2.6948e-06, 9.3749e-06, 0.0000e+00, 2.9356e-04, 4.7765e-06,\n",
      "         2.0333e-04, 0.0000e+00, 4.7610e-04, 0.0000e+00, 0.0000e+00, 4.1183e-05,\n",
      "         0.0000e+00, 1.8949e-05, 1.7569e-08, 1.5617e-08, 0.0000e+00, 3.0389e-04,\n",
      "         6.1793e-05, 4.4166e-05],\n",
      "        [3.2808e-08, 1.2238e-06, 4.2086e-06, 0.0000e+00, 1.3346e-04, 2.3326e-06,\n",
      "         9.6612e-05, 0.0000e+00, 2.1601e-04, 0.0000e+00, 0.0000e+00, 1.8617e-05,\n",
      "         0.0000e+00, 8.4950e-06, 8.6464e-09, 8.2315e-09, 0.0000e+00, 1.4105e-04,\n",
      "         2.8282e-05, 2.0555e-05],\n",
      "        [5.2766e-10, 2.6871e-08, 9.7440e-08, 0.0000e+00, 3.2593e-06, 4.8462e-08,\n",
      "         2.2179e-06, 0.0000e+00, 5.5770e-06, 0.0000e+00, 0.0000e+00, 4.4092e-07,\n",
      "         0.0000e+00, 1.9622e-07, 1.6639e-10, 1.3459e-10, 0.0000e+00, 3.5075e-06,\n",
      "         6.7832e-07, 4.9946e-07],\n",
      "        [3.1098e-11, 2.8404e-10, 2.7989e-09, 0.0000e+00, 5.8640e-08, 1.2267e-09,\n",
      "         4.6074e-08, 0.0000e+00, 1.5695e-07, 0.0000e+00, 0.0000e+00, 9.2674e-09,\n",
      "         0.0000e+00, 5.8045e-09, 9.7221e-12, 8.0377e-12, 0.0000e+00, 8.6095e-08,\n",
      "         9.5601e-09, 1.0590e-08]])}, 9: {'step': tensor(21.), 'exp_avg': tensor([-0.0274,  0.0575, -0.1193,  0.0290, -0.0109,  0.0073, -0.4263,  0.2901,\n",
      "         0.0439, -0.0036]), 'exp_avg_sq': tensor([2.0986e-05, 1.1682e-04, 4.4032e-04, 2.4136e-05, 5.1016e-06, 1.0866e-06,\n",
      "        4.8666e-03, 2.2623e-03, 5.1145e-05, 2.0545e-06])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"\\nOptimizer's state_dict:\")\n",
    "for var_name in model.optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", model.optimizer.state_dict()[var_name])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#############################################################################\n",
    "\n",
    "From here, going to `QuickNN.ipynb` to do the inference of a single controller.\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Saving the model to disk (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(train_batch_size, 1,requires_grad=True)\n",
    "import sys\n",
    "sys.exit(\"Reached kind of end.\")\n",
    "\n",
    "in_model = torch.tensor([10., 10])\n",
    "\n",
    "model_name = '../Models/Model_002_list.onnx'\n",
    "\n",
    "\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  in_model,                  # model input (or a tuple for multiple inputs)\n",
    "                  model_name,                # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input'  : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Loading Model from disk (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model_name = '../Models/Model_002_1.onnx'\n",
    "# model2 = onnx.load(load_model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particular Examples: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PredictController(trim, model, scalerX=scalerX, scalery=scalery):\n",
    "def PredictController(trim, model, scalerX=scalerX):\n",
    "    \"\"\"\n",
    "    Function that receives the trim state vector and generates a prediction of the appropriate\n",
    "    controller based on the trained model 'model'.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    trim: State in the flight envelope\n",
    "    model: Network used\n",
    "    scalerX: scaler used for the features list from the dataset\n",
    "    scalery: scaler used for the outputs list from the dataset\n",
    "    \"\"\"\n",
    "    trim = np.array(trim).reshape(1,-1)\n",
    "    features = scalerX.transform(trim)\n",
    "    out_pred = model(torch.Tensor(features))    # torch.Tensor([1,10])\n",
    "    # K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "    K_comps = out_pred.detach().numpy()\n",
    "    state_dim = K_comps.size    # 10\n",
    "    return K_comps.reshape(2, int(state_dim/2))\n",
    "\n",
    "\n",
    "def ExportSingleController(filename='ExportedController.csv', K=0):\n",
    "    np.savetxt(filename, K, delimiter=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting `Single Controller` based on single flight conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.6461666e-01 -1.7474092e+00  1.5793829e+00 -3.8410774e-03\n",
      "   2.5257075e-01]\n",
      " [-7.2058612e-03  1.7754954e+00 -2.9745905e+01 -7.7651601e+00\n",
      "  -9.2721909e-01]]\n"
     ]
    }
   ],
   "source": [
    "trim_conditions = [18.99, 1492]\n",
    "K = PredictController(trim_conditions, model)\n",
    "print(K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting that single controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trim_conditions = [18.99, 1492];\n",
      "controllername = 'SingleController_002_test2_checkgood-18.99-1492.csv';\n"
     ]
    }
   ],
   "source": [
    "path = '../Controllers/'\n",
    "basename = 'SingleController_002_test2_checkgood'\n",
    "stringV = str(trim_conditions[0])\n",
    "stringH = str(trim_conditions[1])\n",
    "fullname = path + basename + '-' + stringV + '-' + stringH + '.csv'\n",
    "\n",
    "ExportSingleController(filename=fullname, K=K)\n",
    "\n",
    "# TO PASTE TO MATLAB:\n",
    "print('trim_conditions = ' + str(trim_conditions) + ';')\n",
    "print(\"controllername = '\" + basename + \"-\" + stringV + \"-\" + stringH + \".csv';\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the `Predicted Controllers` from the testing data to exporting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(15, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.57291739e-312, 8.58140252e-312, 1.23714038e-319, ...,\n",
       "        3.02907761e-152, 2.31462645e-152, 1.80723903e+185],\n",
       "       [4.44732411e+252, 8.06742686e+276, 5.56319841e+180, ...,\n",
       "        2.86745443e+161, 2.59459186e+161, 6.21452776e+175],\n",
       "       [1.11493090e+277, 6.22651684e+228, 6.50949581e+252, ...,\n",
       "        1.23039479e+224, 6.29199815e+233, 4.63456040e+228],\n",
       "       ...,\n",
       "       [1.96631590e-153, 1.51437960e+256, 6.19640460e+223, ...,\n",
       "        3.28083902e+199, 1.40653076e+142, 8.37981733e+276],\n",
       "       [3.03426193e-086, 1.33716990e-152, 1.28625698e+248, ...,\n",
       "        6.36697561e+151, 4.81127985e+151, 2.41799184e+198],\n",
       "       [8.37981727e+276, 6.15310389e+223, 1.78711426e+161, ...,\n",
       "        2.12690333e-259, 9.70378172e+189, 2.46636231e-154]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GETTING A PREDICTED CONTROLLER FOR EVERY CONDITION IN THE TEST DATA\n",
    "OUTMATRIX =  np.empty((nsamples, 10))\n",
    "# reach = 0\n",
    "for idx, (features, outputs) in enumerate(test_loader):\n",
    "    # Controller prediction:\n",
    "    out_pred = model(features)\n",
    "    # print(out_pred.shape)\n",
    "    np.append(OUTMATRIX, out_pred.detach().numpy(), axis=0)\n",
    "    print(out_pred.detach().numpy().shape)\n",
    "# # K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "# K_comps = out_pred.detach().numpy()\n",
    "# # # Conditions\n",
    "# conditions = scalerX.inverse_transform(features)\n",
    "# add = np.concatenate((conditions, K_comps), axis=1)\n",
    "# # OUTMATRIX[reach:reach+len(features),0:12] = np.concatenate((conditions, K_comps), axis=1)\n",
    "# # reach += len(features)\n",
    "# np.append(OUTMATRIX, add, axis=0)\n",
    "# # if idx == 1: print(add.shape)\n",
    "# # trim = np.array(trim).reshape(1,-1)\n",
    "# # features = scalerX.transform(trim)\n",
    "# # out_pred = model(torch.Tensor(features))    # torch.Tensor([1,10])\n",
    "# # # K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "# # K_comps = out_pred.detach().numpy()\n",
    "# # state_dim = K_comps.size    # 10\n",
    "# # return K_comps.reshape(2, int(state_dim/2))\n",
    "# # if idx == 0 : print(K_comps[0]); print(scalerX.inverse_transform(features)[0])\n",
    "# # print(conditions)\n",
    "# # if idx == 0 : print(scalerX.inverse_transform(features))\n",
    "OUTMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_controllers_name = 'PredictedControllers_002_test1.csv';\n",
    "path = '../Controllers/'\n",
    "np.savetxt(path + predicted_controllers_name, OUTMATRIX, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "da38062997892a68ae88df3a1549a85ff68f4e3a875c1f51aead31b07f2af4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

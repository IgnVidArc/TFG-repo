{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/mlearning-ai/create-a-neural-network-with-pytorch-lightning-in-just-100-lines-of-code-43eccbf3fba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REPORT\n",
    "#### 08/05/23\n",
    "Intento de hacer que la entrada de la red sea un ndarray o algo así, para ver ai guardándola, consigo que me la lead matlab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "\n",
    "# data handling\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "# saving models\n",
    "import torch.onnx\n",
    "import onnx\n",
    "\n",
    "\n",
    "# logging metrics output\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# import tensorboard\n",
    "\n",
    "# else:\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDataset(Dataset):\n",
    "    \"Geting features and outputs ndarray from file.\"\n",
    "    def __init__(self, filename, ninputs, noutputs, delimiter: str=','):\n",
    "        # data loading\n",
    "        xy = np.loadtxt(filename, delimiter=delimiter, dtype=np.float32)\n",
    "        self.X = xy[:, :ninputs]\n",
    "        self.y = xy[:, ninputs:ninputs+noutputs]\n",
    "        self.n_samples = xy.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    \n",
    "class DatasetFromXy(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "        self.n_samples = X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1016\n",
      "Number of testing samples:   255\n"
     ]
    }
   ],
   "source": [
    "# DATASET GENERATION\n",
    "filename = '../Datasets/dataset_002.csv'\n",
    "ninputs = 2\n",
    "noutputs = 10\n",
    "\n",
    "data_raw = GetDataset(filename=filename, ninputs=ninputs, noutputs=noutputs)\n",
    "X_raw = data_raw.X\n",
    "y_raw = data_raw.y\n",
    "\n",
    "scalerX = StandardScaler()\n",
    "X_scaled = scalerX.fit_transform(X_raw)\n",
    "# y_scaled = scalery.fit_transform(y_raw)\n",
    "# y_scaled = copy.deepcopy(y_raw)\n",
    "\n",
    "data_scaled = DatasetFromXy(X_scaled, y_raw)\n",
    "\n",
    "test_set, train_set = random_split(data_scaled, lengths=[.2,.8], generator=torch.Generator())\n",
    "\n",
    "print(f'Number of training samples: {len(train_set):4}\\nNumber of testing samples: {len(test_set):5}')\n",
    "nsamples = len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATALOADERS AND TRAIN/TEST BATCHES\n",
    "train_batch_size = 20\n",
    "test_batch_size = 20\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_set, batch_size=test_batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2]). \n",
      "This means un input tiene tamaño [1,2], es decir, es vector fila.\n"
     ]
    }
   ],
   "source": [
    "ans = next(iter(train_loader))[0].shape\n",
    "print(f\"{ans} \\nThis means un input tiene tamaño [1,2], es decir, es vector fila.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK DEFINITION\n",
    "class Network(pl.LightningModule):\n",
    "    def __init__(self, input_size, output_size, hidden_layers, learning_rate, drop_p=0.5):\n",
    "        ''' Builds a fully connected network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of the input layer.\n",
    "            output_size: integer, size of the output layer.\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers.\n",
    "            learning_rate: learning rate for the optimizer.\n",
    "            drop_p: float = 0.5, drop out probability.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # Input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        # Ouput layer\n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        # Dropout probabilty\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "\n",
    "        # Loss function\n",
    "        self.loss_fun = nn.MSELoss()    # Mean Squared Error\n",
    "\n",
    "        # Optimizer learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # extra: monitoring training loss\n",
    "        # self.training_loss = []\n",
    "        # self.test_batch_idx = []\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits.'''\n",
    "        x = torch.Tensor(x)\n",
    "        for each in self.hidden_layers:\n",
    "            x = F.relu(each(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        \"Definition of the training loop.\"\n",
    "        X, y = train_batch                  # (extracting features and outputs)\n",
    "        # y = y.type(torch.float32)         # (just in case)\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()  # \n",
    "        # compute loss\n",
    "        loss = self.loss_fun(y_pred, y)     # \n",
    "        self.log_dict({'train_loss': loss}, on_step=False, on_epoch=True, prog_bar=True,\n",
    "                      logger=True, enable_graph=True)\n",
    "        \n",
    "        # extra: monitoring training loss:\n",
    "        # self.training_loss.append(np.mean(loss.item()))\n",
    "        # self.test_batch_idx.append(batch_idx)\n",
    "        # extra:\n",
    "        # writer.add_scalar('Train Loss', loss)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "        X, y = test_batch\n",
    "        # forward pass\n",
    "        y_pred = self.forward(X).squeeze()        \n",
    "        # compute metrics\n",
    "        loss = self.loss_fun(y_pred, y)\n",
    "        r2 = r2_score(y_pred, y)\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred, y))\n",
    "        self.log_dict({'Cost function': loss, 'r2': r2, 'Root Mean Square Error': rmse},\n",
    "                      on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK DEFINITION\n",
    "\n",
    "# Number of layers and their sizes:\n",
    "input_size = ninputs\n",
    "output_size = noutputs\n",
    "hidden_layers = [20] # [32, 64, 64, 32]\n",
    "\n",
    "# Other hyperparameters:\n",
    "max_epochs = 500\n",
    "lr = 0.0001\n",
    "drop_p = 0.2\n",
    "\n",
    "model = Network(input_size=input_size, output_size=output_size, hidden_layers=hidden_layers,\n",
    "                learning_rate=lr, drop_p=drop_p)\n",
    "\n",
    "# Including early stoping: `patience` is the key parameter here.\n",
    "patience = 20\n",
    "early_stop_callback = EarlyStopping(monitor=\"train_loss\", min_delta=0.00, patience=patience, verbose=True, mode=\"min\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name          | Type       | Params\n",
      "---------------------------------------------\n",
      "0 | hidden_layers | ModuleList | 60    \n",
      "1 | output        | Linear     | 210   \n",
      "2 | dropout       | Dropout    | 0     \n",
      "3 | loss_fun      | MSELoss    | 0     \n",
      "---------------------------------------------\n",
      "270       Trainable params\n",
      "0         Non-trainable params\n",
      "270       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f430f572e94b739edb4f221f1efbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric train_loss improved. New best score: 166.211\n",
      "Metric train_loss improved by 0.428 >= min_delta = 0.0. New best score: 165.782\n",
      "Metric train_loss improved by 0.300 >= min_delta = 0.0. New best score: 165.482\n",
      "Metric train_loss improved by 0.332 >= min_delta = 0.0. New best score: 165.150\n",
      "Metric train_loss improved by 0.303 >= min_delta = 0.0. New best score: 164.847\n",
      "Metric train_loss improved by 0.305 >= min_delta = 0.0. New best score: 164.542\n",
      "Metric train_loss improved by 0.390 >= min_delta = 0.0. New best score: 164.152\n",
      "Metric train_loss improved by 0.325 >= min_delta = 0.0. New best score: 163.827\n",
      "Metric train_loss improved by 0.339 >= min_delta = 0.0. New best score: 163.488\n",
      "Metric train_loss improved by 0.356 >= min_delta = 0.0. New best score: 163.133\n",
      "Metric train_loss improved by 0.356 >= min_delta = 0.0. New best score: 162.777\n",
      "Metric train_loss improved by 0.260 >= min_delta = 0.0. New best score: 162.517\n",
      "Metric train_loss improved by 0.380 >= min_delta = 0.0. New best score: 162.137\n",
      "Metric train_loss improved by 0.358 >= min_delta = 0.0. New best score: 161.779\n",
      "Metric train_loss improved by 0.352 >= min_delta = 0.0. New best score: 161.428\n",
      "Metric train_loss improved by 0.379 >= min_delta = 0.0. New best score: 161.049\n",
      "Metric train_loss improved by 0.420 >= min_delta = 0.0. New best score: 160.629\n",
      "Metric train_loss improved by 0.332 >= min_delta = 0.0. New best score: 160.297\n",
      "Metric train_loss improved by 0.390 >= min_delta = 0.0. New best score: 159.907\n",
      "Metric train_loss improved by 0.406 >= min_delta = 0.0. New best score: 159.501\n",
      "Metric train_loss improved by 0.336 >= min_delta = 0.0. New best score: 159.165\n",
      "Metric train_loss improved by 0.524 >= min_delta = 0.0. New best score: 158.641\n",
      "Metric train_loss improved by 0.446 >= min_delta = 0.0. New best score: 158.196\n",
      "Metric train_loss improved by 0.365 >= min_delta = 0.0. New best score: 157.830\n",
      "Metric train_loss improved by 0.394 >= min_delta = 0.0. New best score: 157.436\n",
      "Metric train_loss improved by 0.416 >= min_delta = 0.0. New best score: 157.020\n",
      "Metric train_loss improved by 0.539 >= min_delta = 0.0. New best score: 156.480\n",
      "Metric train_loss improved by 0.469 >= min_delta = 0.0. New best score: 156.012\n",
      "Metric train_loss improved by 0.391 >= min_delta = 0.0. New best score: 155.621\n",
      "Metric train_loss improved by 0.487 >= min_delta = 0.0. New best score: 155.133\n",
      "Metric train_loss improved by 0.638 >= min_delta = 0.0. New best score: 154.496\n",
      "Metric train_loss improved by 0.368 >= min_delta = 0.0. New best score: 154.128\n",
      "Metric train_loss improved by 0.586 >= min_delta = 0.0. New best score: 153.542\n",
      "Metric train_loss improved by 0.457 >= min_delta = 0.0. New best score: 153.085\n",
      "Metric train_loss improved by 0.380 >= min_delta = 0.0. New best score: 152.706\n",
      "Metric train_loss improved by 0.676 >= min_delta = 0.0. New best score: 152.030\n",
      "Metric train_loss improved by 0.558 >= min_delta = 0.0. New best score: 151.472\n",
      "Metric train_loss improved by 0.598 >= min_delta = 0.0. New best score: 150.873\n",
      "Metric train_loss improved by 0.413 >= min_delta = 0.0. New best score: 150.461\n",
      "Metric train_loss improved by 0.645 >= min_delta = 0.0. New best score: 149.816\n",
      "Metric train_loss improved by 0.473 >= min_delta = 0.0. New best score: 149.342\n",
      "Metric train_loss improved by 0.631 >= min_delta = 0.0. New best score: 148.712\n",
      "Metric train_loss improved by 0.670 >= min_delta = 0.0. New best score: 148.042\n",
      "Metric train_loss improved by 0.487 >= min_delta = 0.0. New best score: 147.554\n",
      "Metric train_loss improved by 0.560 >= min_delta = 0.0. New best score: 146.994\n",
      "Metric train_loss improved by 0.649 >= min_delta = 0.0. New best score: 146.346\n",
      "Metric train_loss improved by 0.604 >= min_delta = 0.0. New best score: 145.742\n",
      "Metric train_loss improved by 0.549 >= min_delta = 0.0. New best score: 145.193\n",
      "Metric train_loss improved by 0.833 >= min_delta = 0.0. New best score: 144.360\n",
      "Metric train_loss improved by 0.639 >= min_delta = 0.0. New best score: 143.721\n",
      "Metric train_loss improved by 0.694 >= min_delta = 0.0. New best score: 143.027\n",
      "Metric train_loss improved by 0.500 >= min_delta = 0.0. New best score: 142.527\n",
      "Metric train_loss improved by 0.668 >= min_delta = 0.0. New best score: 141.859\n",
      "Metric train_loss improved by 0.438 >= min_delta = 0.0. New best score: 141.421\n",
      "Metric train_loss improved by 0.795 >= min_delta = 0.0. New best score: 140.625\n",
      "Metric train_loss improved by 0.710 >= min_delta = 0.0. New best score: 139.915\n",
      "Metric train_loss improved by 0.599 >= min_delta = 0.0. New best score: 139.316\n",
      "Metric train_loss improved by 0.904 >= min_delta = 0.0. New best score: 138.411\n",
      "Metric train_loss improved by 0.510 >= min_delta = 0.0. New best score: 137.901\n",
      "Metric train_loss improved by 0.944 >= min_delta = 0.0. New best score: 136.957\n",
      "Metric train_loss improved by 0.541 >= min_delta = 0.0. New best score: 136.416\n",
      "Metric train_loss improved by 0.860 >= min_delta = 0.0. New best score: 135.556\n",
      "Metric train_loss improved by 0.763 >= min_delta = 0.0. New best score: 134.793\n",
      "Metric train_loss improved by 0.438 >= min_delta = 0.0. New best score: 134.354\n",
      "Metric train_loss improved by 0.863 >= min_delta = 0.0. New best score: 133.491\n",
      "Metric train_loss improved by 0.758 >= min_delta = 0.0. New best score: 132.733\n",
      "Metric train_loss improved by 0.690 >= min_delta = 0.0. New best score: 132.043\n",
      "Metric train_loss improved by 0.788 >= min_delta = 0.0. New best score: 131.256\n",
      "Metric train_loss improved by 0.625 >= min_delta = 0.0. New best score: 130.631\n",
      "Metric train_loss improved by 0.546 >= min_delta = 0.0. New best score: 130.085\n",
      "Metric train_loss improved by 0.969 >= min_delta = 0.0. New best score: 129.116\n",
      "Metric train_loss improved by 0.485 >= min_delta = 0.0. New best score: 128.631\n",
      "Metric train_loss improved by 0.533 >= min_delta = 0.0. New best score: 128.098\n",
      "Metric train_loss improved by 1.226 >= min_delta = 0.0. New best score: 126.872\n",
      "Metric train_loss improved by 0.443 >= min_delta = 0.0. New best score: 126.429\n",
      "Metric train_loss improved by 0.929 >= min_delta = 0.0. New best score: 125.501\n",
      "Metric train_loss improved by 0.791 >= min_delta = 0.0. New best score: 124.710\n",
      "Metric train_loss improved by 0.826 >= min_delta = 0.0. New best score: 123.884\n",
      "Metric train_loss improved by 0.594 >= min_delta = 0.0. New best score: 123.290\n",
      "Metric train_loss improved by 0.805 >= min_delta = 0.0. New best score: 122.485\n",
      "Metric train_loss improved by 0.989 >= min_delta = 0.0. New best score: 121.496\n",
      "Metric train_loss improved by 0.856 >= min_delta = 0.0. New best score: 120.640\n",
      "Metric train_loss improved by 0.568 >= min_delta = 0.0. New best score: 120.073\n",
      "Metric train_loss improved by 1.175 >= min_delta = 0.0. New best score: 118.898\n",
      "Metric train_loss improved by 0.441 >= min_delta = 0.0. New best score: 118.457\n",
      "Metric train_loss improved by 0.893 >= min_delta = 0.0. New best score: 117.564\n",
      "Metric train_loss improved by 0.706 >= min_delta = 0.0. New best score: 116.858\n",
      "Metric train_loss improved by 0.477 >= min_delta = 0.0. New best score: 116.381\n",
      "Metric train_loss improved by 1.074 >= min_delta = 0.0. New best score: 115.307\n",
      "Metric train_loss improved by 0.773 >= min_delta = 0.0. New best score: 114.535\n",
      "Metric train_loss improved by 0.698 >= min_delta = 0.0. New best score: 113.836\n",
      "Metric train_loss improved by 0.474 >= min_delta = 0.0. New best score: 113.363\n",
      "Metric train_loss improved by 1.097 >= min_delta = 0.0. New best score: 112.266\n",
      "Metric train_loss improved by 0.633 >= min_delta = 0.0. New best score: 111.633\n",
      "Metric train_loss improved by 1.149 >= min_delta = 0.0. New best score: 110.484\n",
      "Metric train_loss improved by 0.963 >= min_delta = 0.0. New best score: 109.521\n",
      "Metric train_loss improved by 0.114 >= min_delta = 0.0. New best score: 109.407\n",
      "Metric train_loss improved by 1.194 >= min_delta = 0.0. New best score: 108.213\n",
      "Metric train_loss improved by 0.432 >= min_delta = 0.0. New best score: 107.781\n",
      "Metric train_loss improved by 0.900 >= min_delta = 0.0. New best score: 106.881\n",
      "Metric train_loss improved by 0.694 >= min_delta = 0.0. New best score: 106.187\n",
      "Metric train_loss improved by 0.628 >= min_delta = 0.0. New best score: 105.559\n",
      "Metric train_loss improved by 0.931 >= min_delta = 0.0. New best score: 104.628\n",
      "Metric train_loss improved by 0.579 >= min_delta = 0.0. New best score: 104.049\n",
      "Metric train_loss improved by 1.048 >= min_delta = 0.0. New best score: 103.001\n",
      "Metric train_loss improved by 0.851 >= min_delta = 0.0. New best score: 102.150\n",
      "Metric train_loss improved by 0.802 >= min_delta = 0.0. New best score: 101.347\n",
      "Metric train_loss improved by 0.982 >= min_delta = 0.0. New best score: 100.365\n",
      "Metric train_loss improved by 0.487 >= min_delta = 0.0. New best score: 99.878\n",
      "Metric train_loss improved by 0.782 >= min_delta = 0.0. New best score: 99.095\n",
      "Metric train_loss improved by 1.047 >= min_delta = 0.0. New best score: 98.049\n",
      "Metric train_loss improved by 0.218 >= min_delta = 0.0. New best score: 97.831\n",
      "Metric train_loss improved by 1.127 >= min_delta = 0.0. New best score: 96.704\n",
      "Metric train_loss improved by 0.875 >= min_delta = 0.0. New best score: 95.829\n",
      "Metric train_loss improved by 0.468 >= min_delta = 0.0. New best score: 95.361\n",
      "Metric train_loss improved by 1.280 >= min_delta = 0.0. New best score: 94.080\n",
      "Metric train_loss improved by 0.353 >= min_delta = 0.0. New best score: 93.727\n",
      "Metric train_loss improved by 0.741 >= min_delta = 0.0. New best score: 92.986\n",
      "Metric train_loss improved by 0.863 >= min_delta = 0.0. New best score: 92.123\n",
      "Metric train_loss improved by 0.737 >= min_delta = 0.0. New best score: 91.386\n",
      "Metric train_loss improved by 1.150 >= min_delta = 0.0. New best score: 90.237\n",
      "Metric train_loss improved by 0.588 >= min_delta = 0.0. New best score: 89.649\n",
      "Metric train_loss improved by 0.383 >= min_delta = 0.0. New best score: 89.266\n",
      "Metric train_loss improved by 1.770 >= min_delta = 0.0. New best score: 87.496\n",
      "Metric train_loss improved by 0.081 >= min_delta = 0.0. New best score: 87.415\n",
      "Metric train_loss improved by 0.409 >= min_delta = 0.0. New best score: 87.006\n",
      "Metric train_loss improved by 1.733 >= min_delta = 0.0. New best score: 85.273\n",
      "Metric train_loss improved by 0.873 >= min_delta = 0.0. New best score: 84.400\n",
      "Metric train_loss improved by 0.343 >= min_delta = 0.0. New best score: 84.057\n",
      "Metric train_loss improved by 0.513 >= min_delta = 0.0. New best score: 83.545\n",
      "Metric train_loss improved by 1.410 >= min_delta = 0.0. New best score: 82.135\n",
      "Metric train_loss improved by 0.302 >= min_delta = 0.0. New best score: 81.832\n",
      "Metric train_loss improved by 0.174 >= min_delta = 0.0. New best score: 81.658\n",
      "Metric train_loss improved by 1.199 >= min_delta = 0.0. New best score: 80.459\n",
      "Metric train_loss improved by 0.990 >= min_delta = 0.0. New best score: 79.469\n",
      "Metric train_loss improved by 0.853 >= min_delta = 0.0. New best score: 78.616\n",
      "Metric train_loss improved by 0.932 >= min_delta = 0.0. New best score: 77.684\n",
      "Metric train_loss improved by 0.512 >= min_delta = 0.0. New best score: 77.172\n",
      "Metric train_loss improved by 0.931 >= min_delta = 0.0. New best score: 76.241\n",
      "Metric train_loss improved by 0.717 >= min_delta = 0.0. New best score: 75.524\n",
      "Metric train_loss improved by 0.170 >= min_delta = 0.0. New best score: 75.354\n",
      "Metric train_loss improved by 1.218 >= min_delta = 0.0. New best score: 74.136\n",
      "Metric train_loss improved by 0.220 >= min_delta = 0.0. New best score: 73.915\n",
      "Metric train_loss improved by 0.617 >= min_delta = 0.0. New best score: 73.298\n",
      "Metric train_loss improved by 1.244 >= min_delta = 0.0. New best score: 72.055\n",
      "Metric train_loss improved by 1.504 >= min_delta = 0.0. New best score: 70.550\n",
      "Metric train_loss improved by 0.929 >= min_delta = 0.0. New best score: 69.622\n",
      "Metric train_loss improved by 0.599 >= min_delta = 0.0. New best score: 69.023\n",
      "Metric train_loss improved by 1.632 >= min_delta = 0.0. New best score: 67.391\n",
      "Metric train_loss improved by 0.184 >= min_delta = 0.0. New best score: 67.207\n",
      "Metric train_loss improved by 0.550 >= min_delta = 0.0. New best score: 66.656\n",
      "Metric train_loss improved by 1.371 >= min_delta = 0.0. New best score: 65.286\n",
      "Metric train_loss improved by 0.262 >= min_delta = 0.0. New best score: 65.024\n",
      "Metric train_loss improved by 1.291 >= min_delta = 0.0. New best score: 63.732\n",
      "Metric train_loss improved by 0.581 >= min_delta = 0.0. New best score: 63.152\n",
      "Metric train_loss improved by 0.382 >= min_delta = 0.0. New best score: 62.770\n",
      "Metric train_loss improved by 0.497 >= min_delta = 0.0. New best score: 62.273\n",
      "Metric train_loss improved by 0.798 >= min_delta = 0.0. New best score: 61.476\n",
      "Metric train_loss improved by 0.152 >= min_delta = 0.0. New best score: 61.324\n",
      "Metric train_loss improved by 1.194 >= min_delta = 0.0. New best score: 60.130\n",
      "Metric train_loss improved by 0.862 >= min_delta = 0.0. New best score: 59.268\n",
      "Metric train_loss improved by 0.243 >= min_delta = 0.0. New best score: 59.025\n",
      "Metric train_loss improved by 2.036 >= min_delta = 0.0. New best score: 56.988\n",
      "Metric train_loss improved by 1.085 >= min_delta = 0.0. New best score: 55.903\n",
      "Metric train_loss improved by 0.906 >= min_delta = 0.0. New best score: 54.997\n",
      "Metric train_loss improved by 0.462 >= min_delta = 0.0. New best score: 54.535\n",
      "Metric train_loss improved by 0.246 >= min_delta = 0.0. New best score: 54.288\n",
      "Metric train_loss improved by 1.707 >= min_delta = 0.0. New best score: 52.581\n",
      "Metric train_loss improved by 0.030 >= min_delta = 0.0. New best score: 52.551\n",
      "Metric train_loss improved by 0.572 >= min_delta = 0.0. New best score: 51.978\n",
      "Metric train_loss improved by 0.214 >= min_delta = 0.0. New best score: 51.765\n",
      "Metric train_loss improved by 2.050 >= min_delta = 0.0. New best score: 49.715\n",
      "Metric train_loss improved by 0.101 >= min_delta = 0.0. New best score: 49.614\n",
      "Metric train_loss improved by 1.154 >= min_delta = 0.0. New best score: 48.460\n",
      "Metric train_loss improved by 0.242 >= min_delta = 0.0. New best score: 48.218\n",
      "Metric train_loss improved by 0.984 >= min_delta = 0.0. New best score: 47.234\n",
      "Metric train_loss improved by 1.050 >= min_delta = 0.0. New best score: 46.184\n",
      "Metric train_loss improved by 0.271 >= min_delta = 0.0. New best score: 45.914\n",
      "Metric train_loss improved by 0.596 >= min_delta = 0.0. New best score: 45.318\n",
      "Metric train_loss improved by 1.315 >= min_delta = 0.0. New best score: 44.003\n",
      "Metric train_loss improved by 0.233 >= min_delta = 0.0. New best score: 43.770\n",
      "Metric train_loss improved by 0.982 >= min_delta = 0.0. New best score: 42.788\n",
      "Metric train_loss improved by 0.812 >= min_delta = 0.0. New best score: 41.976\n",
      "Metric train_loss improved by 0.407 >= min_delta = 0.0. New best score: 41.569\n",
      "Metric train_loss improved by 0.053 >= min_delta = 0.0. New best score: 41.516\n",
      "Metric train_loss improved by 1.594 >= min_delta = 0.0. New best score: 39.922\n",
      "Metric train_loss improved by 0.618 >= min_delta = 0.0. New best score: 39.304\n",
      "Metric train_loss improved by 0.342 >= min_delta = 0.0. New best score: 38.961\n",
      "Metric train_loss improved by 1.110 >= min_delta = 0.0. New best score: 37.852\n",
      "Metric train_loss improved by 1.553 >= min_delta = 0.0. New best score: 36.298\n",
      "Metric train_loss improved by 0.426 >= min_delta = 0.0. New best score: 35.873\n",
      "Metric train_loss improved by 0.509 >= min_delta = 0.0. New best score: 35.364\n",
      "Metric train_loss improved by 0.822 >= min_delta = 0.0. New best score: 34.542\n",
      "Metric train_loss improved by 0.657 >= min_delta = 0.0. New best score: 33.885\n",
      "Metric train_loss improved by 0.779 >= min_delta = 0.0. New best score: 33.106\n",
      "Metric train_loss improved by 0.944 >= min_delta = 0.0. New best score: 32.162\n",
      "Metric train_loss improved by 1.037 >= min_delta = 0.0. New best score: 31.125\n",
      "Metric train_loss improved by 0.554 >= min_delta = 0.0. New best score: 30.571\n",
      "Metric train_loss improved by 0.837 >= min_delta = 0.0. New best score: 29.734\n",
      "Metric train_loss improved by 0.454 >= min_delta = 0.0. New best score: 29.280\n",
      "Metric train_loss improved by 0.102 >= min_delta = 0.0. New best score: 29.178\n",
      "Metric train_loss improved by 1.541 >= min_delta = 0.0. New best score: 27.638\n",
      "Metric train_loss improved by 0.218 >= min_delta = 0.0. New best score: 27.420\n",
      "Metric train_loss improved by 0.714 >= min_delta = 0.0. New best score: 26.706\n",
      "Metric train_loss improved by 0.549 >= min_delta = 0.0. New best score: 26.156\n",
      "Metric train_loss improved by 0.547 >= min_delta = 0.0. New best score: 25.610\n",
      "Metric train_loss improved by 0.269 >= min_delta = 0.0. New best score: 25.340\n",
      "Metric train_loss improved by 1.095 >= min_delta = 0.0. New best score: 24.245\n",
      "Metric train_loss improved by 0.312 >= min_delta = 0.0. New best score: 23.933\n",
      "Metric train_loss improved by 0.375 >= min_delta = 0.0. New best score: 23.558\n",
      "Metric train_loss improved by 0.634 >= min_delta = 0.0. New best score: 22.925\n",
      "Metric train_loss improved by 0.672 >= min_delta = 0.0. New best score: 22.253\n",
      "Metric train_loss improved by 0.327 >= min_delta = 0.0. New best score: 21.926\n",
      "Metric train_loss improved by 1.321 >= min_delta = 0.0. New best score: 20.605\n",
      "Metric train_loss improved by 0.056 >= min_delta = 0.0. New best score: 20.549\n",
      "Metric train_loss improved by 0.415 >= min_delta = 0.0. New best score: 20.135\n",
      "Metric train_loss improved by 1.413 >= min_delta = 0.0. New best score: 18.721\n",
      "Metric train_loss improved by 0.403 >= min_delta = 0.0. New best score: 18.319\n",
      "Metric train_loss improved by 0.338 >= min_delta = 0.0. New best score: 17.981\n",
      "Metric train_loss improved by 0.927 >= min_delta = 0.0. New best score: 17.054\n",
      "Metric train_loss improved by 0.127 >= min_delta = 0.0. New best score: 16.927\n",
      "Metric train_loss improved by 0.335 >= min_delta = 0.0. New best score: 16.592\n",
      "Metric train_loss improved by 0.571 >= min_delta = 0.0. New best score: 16.021\n",
      "Metric train_loss improved by 0.366 >= min_delta = 0.0. New best score: 15.655\n",
      "Metric train_loss improved by 0.158 >= min_delta = 0.0. New best score: 15.497\n",
      "Metric train_loss improved by 0.923 >= min_delta = 0.0. New best score: 14.574\n",
      "Metric train_loss improved by 0.097 >= min_delta = 0.0. New best score: 14.477\n",
      "Metric train_loss improved by 0.650 >= min_delta = 0.0. New best score: 13.827\n",
      "Metric train_loss improved by 0.584 >= min_delta = 0.0. New best score: 13.243\n",
      "Metric train_loss improved by 0.154 >= min_delta = 0.0. New best score: 13.089\n",
      "Metric train_loss improved by 0.267 >= min_delta = 0.0. New best score: 12.822\n",
      "Metric train_loss improved by 0.575 >= min_delta = 0.0. New best score: 12.247\n",
      "Metric train_loss improved by 0.607 >= min_delta = 0.0. New best score: 11.640\n",
      "Metric train_loss improved by 0.003 >= min_delta = 0.0. New best score: 11.637\n",
      "Metric train_loss improved by 0.015 >= min_delta = 0.0. New best score: 11.622\n",
      "Metric train_loss improved by 0.627 >= min_delta = 0.0. New best score: 10.995\n",
      "Metric train_loss improved by 0.166 >= min_delta = 0.0. New best score: 10.829\n",
      "Metric train_loss improved by 0.234 >= min_delta = 0.0. New best score: 10.594\n",
      "Metric train_loss improved by 0.193 >= min_delta = 0.0. New best score: 10.401\n",
      "Metric train_loss improved by 0.687 >= min_delta = 0.0. New best score: 9.714\n",
      "Metric train_loss improved by 0.075 >= min_delta = 0.0. New best score: 9.639\n",
      "Metric train_loss improved by 0.353 >= min_delta = 0.0. New best score: 9.286\n",
      "Metric train_loss improved by 0.204 >= min_delta = 0.0. New best score: 9.082\n",
      "Metric train_loss improved by 0.088 >= min_delta = 0.0. New best score: 8.994\n",
      "Metric train_loss improved by 0.067 >= min_delta = 0.0. New best score: 8.928\n",
      "Metric train_loss improved by 0.129 >= min_delta = 0.0. New best score: 8.798\n",
      "Metric train_loss improved by 0.248 >= min_delta = 0.0. New best score: 8.551\n",
      "Metric train_loss improved by 0.020 >= min_delta = 0.0. New best score: 8.531\n",
      "Metric train_loss improved by 0.097 >= min_delta = 0.0. New best score: 8.433\n",
      "Metric train_loss improved by 0.823 >= min_delta = 0.0. New best score: 7.610\n",
      "Metric train_loss improved by 0.161 >= min_delta = 0.0. New best score: 7.449\n",
      "Metric train_loss improved by 0.072 >= min_delta = 0.0. New best score: 7.377\n",
      "Metric train_loss improved by 0.566 >= min_delta = 0.0. New best score: 6.810\n",
      "Metric train_loss improved by 0.005 >= min_delta = 0.0. New best score: 6.806\n",
      "Metric train_loss improved by 0.107 >= min_delta = 0.0. New best score: 6.699\n",
      "Metric train_loss improved by 0.339 >= min_delta = 0.0. New best score: 6.360\n",
      "Metric train_loss improved by 0.114 >= min_delta = 0.0. New best score: 6.246\n",
      "Metric train_loss improved by 0.038 >= min_delta = 0.0. New best score: 6.207\n",
      "Metric train_loss improved by 0.023 >= min_delta = 0.0. New best score: 6.185\n",
      "Metric train_loss improved by 0.085 >= min_delta = 0.0. New best score: 6.100\n",
      "Metric train_loss improved by 0.058 >= min_delta = 0.0. New best score: 6.042\n",
      "Metric train_loss improved by 0.251 >= min_delta = 0.0. New best score: 5.791\n",
      "Metric train_loss improved by 0.032 >= min_delta = 0.0. New best score: 5.758\n",
      "Metric train_loss improved by 0.059 >= min_delta = 0.0. New best score: 5.699\n",
      "Metric train_loss improved by 0.288 >= min_delta = 0.0. New best score: 5.412\n",
      "Metric train_loss improved by 0.029 >= min_delta = 0.0. New best score: 5.383\n",
      "Metric train_loss improved by 0.148 >= min_delta = 0.0. New best score: 5.235\n",
      "Metric train_loss improved by 0.025 >= min_delta = 0.0. New best score: 5.209\n",
      "Metric train_loss improved by 0.120 >= min_delta = 0.0. New best score: 5.089\n",
      "Metric train_loss improved by 0.267 >= min_delta = 0.0. New best score: 4.822\n",
      "Metric train_loss improved by 0.086 >= min_delta = 0.0. New best score: 4.736\n",
      "Metric train_loss improved by 0.099 >= min_delta = 0.0. New best score: 4.637\n",
      "Metric train_loss improved by 0.089 >= min_delta = 0.0. New best score: 4.548\n",
      "Metric train_loss improved by 0.033 >= min_delta = 0.0. New best score: 4.515\n",
      "Monitored metric train_loss did not improve in the last 20 records. Best score: 4.515. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "# DEFINITION OF THE TRAINER\n",
    "trainer = pl.Trainer(accelerator='cpu', devices=1, max_epochs=max_epochs,\n",
    "                     callbacks=[early_stop_callback], log_every_n_steps=8)\n",
    "\n",
    "# TRAINING\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "# writer.flush()\n",
    "# writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version_number = 23\n",
    "# metrics = np.loadtxt(fname='./lightning_logs/version_' + str(version_number) + '/metrics.csv',\n",
    "#                      delimiter=',', skiprows=1, usecols=2)\n",
    "# # train_losss = metrics[:,0]\n",
    "# # epochs = metrics[:,1]\n",
    "# # steps = metrics[:,2]\n",
    "# # plt.figure()\n",
    "# # plt.plot(epochs, train_losss)\n",
    "# # plt.xlabel('Epoch')\n",
    "# # plt.ylabel('Training Loss')\n",
    "# # plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:478: PossibleUserWarning: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\ignac\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f8115aa61c40f79b85e8be79c23010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Cost function         0.5950925350189209\n",
      " Root Mean Square Error     0.7664029002189636\n",
      "           r2              0.008631947429551225\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Cost function': 0.5950925350189209,\n",
       "  'r2': 0.008631947429551225,\n",
       "  'Root Mean Square Error': 0.7664029002189636}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST OUTPUT\n",
    "# type(test_loader)\n",
    "trainer.test(model=model, dataloaders=test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.0 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignac\\AppData\\Local\\Temp\\ipykernel_37620\\2277221715.py:41: TracerWarning: torch.Tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  x = torch.Tensor(x)\n"
     ]
    }
   ],
   "source": [
    "in_model = torch.randn(train_batch_size, 2, requires_grad=True)\n",
    "\n",
    "model_name = '../Models/Model_002_3.onnx'\n",
    "\n",
    "\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  in_model,                  # model input (or a tuple for multiple inputs)\n",
    "                  model_name,                # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  dynamic_axes = {'input'  : {0 : 'batch_size'},    # variable length axes\n",
    "                                  'output' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Loading Model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_name = '../Models/Model_002_1.onnx'\n",
    "model2 = onnx.load(load_model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particular Examples: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PredictController(trim, model, scalerX=scalerX, scalery=scalery):\n",
    "def PredictController(trim, model, scalerX=scalerX):\n",
    "    \"\"\"\n",
    "    Function that receives the trim state vector and generates a prediction of the appropriate\n",
    "    controller based on the trained model 'model'.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    trim: State in the flight envelope\n",
    "    model: Network used\n",
    "    scalerX: scaler used for the features list from the dataset\n",
    "    scalery: scaler used for the outputs list from the dataset\n",
    "    \"\"\"\n",
    "    trim = np.array(trim).reshape(1,-1)\n",
    "    features = scalerX.transform(trim)\n",
    "    out_pred = model(torch.Tensor(features))    # torch.Tensor([1,10])\n",
    "    # K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "    K_comps = out_pred.detach().numpy()\n",
    "    state_dim = K_comps.size    # 10\n",
    "    return K_comps.reshape(2, int(state_dim/2))\n",
    "\n",
    "\n",
    "def ExportSingleController(filename='ExportedController.csv', K=0):\n",
    "    np.savetxt(filename, K, delimiter=\",\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting `Single Controller` based on single flight conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.6461666e-01 -1.7474092e+00  1.5793829e+00 -3.8410774e-03\n",
      "   2.5257075e-01]\n",
      " [-7.2058612e-03  1.7754954e+00 -2.9745905e+01 -7.7651601e+00\n",
      "  -9.2721909e-01]]\n"
     ]
    }
   ],
   "source": [
    "trim_conditions = [18.99, 1492]\n",
    "K = PredictController(trim_conditions, model)\n",
    "print(K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting that single controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trim_conditions = [18.99, 1492];\n",
      "controllername = 'SingleController_002_test2_checkgood-18.99-1492.csv';\n"
     ]
    }
   ],
   "source": [
    "path = '../Controllers/'\n",
    "basename = 'SingleController_002_test2_checkgood'\n",
    "stringV = str(trim_conditions[0])\n",
    "stringH = str(trim_conditions[1])\n",
    "fullname = path + basename + '-' + stringV + '-' + stringH + '.csv'\n",
    "\n",
    "ExportSingleController(filename=fullname, K=K)\n",
    "\n",
    "# TO PASTE TO MATLAB:\n",
    "print('trim_conditions = ' + str(trim_conditions) + ';')\n",
    "print(\"controllername = '\" + basename + \"-\" + stringV + \"-\" + stringH + \".csv';\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the `Predicted Controllers` from the testing data to exporting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(20, 10)\n",
      "(15, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.57291739e-312, 8.58140252e-312, 1.23714038e-319, ...,\n",
       "        3.02907761e-152, 2.31462645e-152, 1.80723903e+185],\n",
       "       [4.44732411e+252, 8.06742686e+276, 5.56319841e+180, ...,\n",
       "        2.86745443e+161, 2.59459186e+161, 6.21452776e+175],\n",
       "       [1.11493090e+277, 6.22651684e+228, 6.50949581e+252, ...,\n",
       "        1.23039479e+224, 6.29199815e+233, 4.63456040e+228],\n",
       "       ...,\n",
       "       [1.96631590e-153, 1.51437960e+256, 6.19640460e+223, ...,\n",
       "        3.28083902e+199, 1.40653076e+142, 8.37981733e+276],\n",
       "       [3.03426193e-086, 1.33716990e-152, 1.28625698e+248, ...,\n",
       "        6.36697561e+151, 4.81127985e+151, 2.41799184e+198],\n",
       "       [8.37981727e+276, 6.15310389e+223, 1.78711426e+161, ...,\n",
       "        2.12690333e-259, 9.70378172e+189, 2.46636231e-154]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GETTING A PREDICTED CONTROLLER FOR EVERY CONDITION IN THE TEST DATA\n",
    "OUTMATRIX =  np.empty((nsamples, 10))\n",
    "# reach = 0\n",
    "for idx, (features, outputs) in enumerate(test_loader):\n",
    "    # Controller prediction:\n",
    "    out_pred = model(features)\n",
    "    # print(out_pred.shape)\n",
    "    np.append(OUTMATRIX, out_pred.detach().numpy(), axis=0)\n",
    "    print(out_pred.detach().numpy().shape)\n",
    "# # K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "# K_comps = out_pred.detach().numpy()\n",
    "# # # Conditions\n",
    "# conditions = scalerX.inverse_transform(features)\n",
    "# add = np.concatenate((conditions, K_comps), axis=1)\n",
    "# # OUTMATRIX[reach:reach+len(features),0:12] = np.concatenate((conditions, K_comps), axis=1)\n",
    "# # reach += len(features)\n",
    "# np.append(OUTMATRIX, add, axis=0)\n",
    "# # if idx == 1: print(add.shape)\n",
    "# # trim = np.array(trim).reshape(1,-1)\n",
    "# # features = scalerX.transform(trim)\n",
    "# # out_pred = model(torch.Tensor(features))    # torch.Tensor([1,10])\n",
    "# # # K_comps = scalery.inverse_transform(out_pred.detach().numpy())\n",
    "# # K_comps = out_pred.detach().numpy()\n",
    "# # state_dim = K_comps.size    # 10\n",
    "# # return K_comps.reshape(2, int(state_dim/2))\n",
    "# # if idx == 0 : print(K_comps[0]); print(scalerX.inverse_transform(features)[0])\n",
    "# # print(conditions)\n",
    "# # if idx == 0 : print(scalerX.inverse_transform(features))\n",
    "OUTMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_controllers_name = 'PredictedControllers_002_test1.csv';\n",
    "path = '../Controllers/'\n",
    "np.savetxt(path + predicted_controllers_name, OUTMATRIX, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "da38062997892a68ae88df3a1549a85ff68f4e3a875c1f51aead31b07f2af4c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
